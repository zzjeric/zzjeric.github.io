{"meta":{"title":"Eric's blog","subtitle":"生如逆旅 一苇以航","description":"Eric's blog","author":"Eric Zhao","url":"http://example.com","root":"/"},"pages":[],"posts":[{"title":"基于kubeadm搭建k8s集群v1.16","slug":"k8s_cluster_deploy_116","date":"2020-02-01T05:33:33.000Z","updated":"2021-06-21T06:38:19.600Z","comments":true,"path":"2020/02/01/k8s_cluster_deploy_116/","link":"","permalink":"http://example.com/2020/02/01/k8s_cluster_deploy_116/","excerpt":"","text":"Kubeadm是k8s官方提供的一个k8s集群搭建和管理工具，能简化很多配置工作。 参考： https://kubernetes.io/zh/docs/reference/setup-tools/kubeadm/kubeadm/ 1 软件版本： Kubeadm： K8s：v1.16 Os： Centos 7.x Kernel： Linux 5.3.7-1.el7.elrepo.x86_64 2 配置虚拟机环境：2.1 检查centos内核版本（所有节点）：1234[root@localhost ~]# cat /etc/redhat-releaseCentOS Linux release 7.2.1511 (Core) [root@localhost ~]# uname -srLinux 3.10.0-327.el7.x86_64 可以看到用的centos7.2，内核是3.x的，版本有点低，如果需要启用ipvs，需要升级内核到最新版本（或者使用Centos 7.6、7.8等比较新的os），升级后内核版本为： 12[root@node1 ~]# uname -srLinux 5.3.7-1.el7.elrepo.x86_64 升级centos内核： 在 CentOS 7 上启用 ELRepo 仓库： 12rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.orgrpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm 使用下面的命令列出可用的内核相关包： 1yum --disablerepo=&quot;*&quot; --enablerepo=&quot;elrepo-kernel&quot; list available 安装最新的主线稳定内核： 1yum --enablerepo=elrepo-kernel install kernel-ml 设置grub默认内核版本： 编辑/etc/default/grub 文件，内容替换为： 123456GRUB_TIMEOUT=5GRUB_DEFAULT=0GRUB_DISABLE_SUBMENU=trueGRUB_TERMINAL_OUTPUT=&quot;console&quot;GRUB_CMDLINE_LINUX=&quot;rd.lvm.lv=centos/root rd.lvm.lv=centos/swap crashkernel=auto rhgb quiet&quot;GRUB_DISABLE_RECOVERY=&quot;true&quot; 运行下面的命令来重新创建内核配置： 1grub2-mkconfig -o /boot/grub2/grub.cfg 然后reboot重启，完成后，用uname -sr重新查看内核版本是否已升级。 参考：https://linux.cn/article-8310-1.html 2.2 配置NTP 服务器（所有节点）123sudo yum -y install ntpsystemctl start ntpdhttps://blog.csdn.net/zhangjie0412/article/details/77935584 2.3 配置hosts（所有节点）在/所有节点的etc/hosts文件中，配置各个节点的ipcat /etc/hosts 123172.18.10.18 node1172.18.10.19 node2172.18.10.20 node3 其中node1作为master节点，node2和node3作为普通节点。 2.4 修改或禁用防火墙开放端口（所有节点）如果各个主机启用了防火墙，需要开放Kubernetes各个组件所需要的端口，可以查看Installing kubeadm中的”Check required ports”一节。 简单起见在各节点禁用防火墙： 12systemctl stop firewalldsystemctl disable firewalld 生产环境下，这里需要考虑一下。 禁用SELINUX： 123setenforce 0vi /etc/selinux/configSELINUX=disabled 创建/etc/sysctl.d/k8s.conf文件，添加如下内容： 123net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward = 1 执行命令使修改生效。 12modprobe br_netfiltersysctl -p /etc/sysctl.d/k8s.conf 2.5 配置ipvs（所有节点）kube-proxy开启ipvs 需要加载一些内核模块，在5.3.7的内核版本，nf_conntrack_ipv4被nf_contrack代替，所以使用下面的命令： 123456789cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF#!/bin/bashmodprobe -- ip_vsmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- ip_vs_shmodprobe -- nf_conntrackEOFchmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep -e ip_vs -e nf_conntrack 各个节点安装ipset和ipvsadm： 12yum install ipsetyum install ipvsadm 2.6 安装docker（所有节点）安装docker的yum源: 1234yum install -y yum-utils device-mapper-persistent-data lvm2yum-config-manager \\ --add-repo \\https://download.docker.com/linux/centos/docker-ce.repo 查看可用的docker版本： 1yum list docker-ce.x86_64 --showduplicates |sort -r 在各节点安装docker最新的的19.03.4版本。 1234567yum makecache fastyum install -y --setopt=obsoletes=0 \\ docker-ce-19.03.4-3.el7systemctl start dockersystemctl enable docker 确认一下iptables filter表中FOWARD链的默认策略(pllicy)为ACCEPT。 1iptables -nvL 修改docker cgroup driver为systemd: 创建或修改/etc/docker/daemon.json： 123&#123; &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]&#125; 重启docker： 1systemctl restart docker 用下面的命令验证一下： 12docker info | grep CgroupCgroup Driver: system 2.7 关闭swap（所有节点）Kubernetes 1.8开始要求关闭系统的Swap，如果不关闭，默认配置下kubelet将无法启动 关闭系统的Swap方法如下: 1swapoff -a 修改 /etc/fstab 文件，注释掉 SWAP 的自动挂载，使用free -m确认swap已经关闭。 swappiness参数调整，修改/etc/sysctl.d/k8s.conf添加下面一行： vm.swappiness=0 执行sysctl -p /etc/sysctl.d/k8s.conf使修改生效。 2.8 安装kubeadm和kubelet（所有节点）配置repo： 12345678910cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpgEOF 安装： 12yum makecache fastyum install -y kubelet kubeadm kubectl 在各节点开机启动kubelet服务： 1systemctl enable kubelet.service 3 使用kubeadm部署k8s3.1 部署master节点3.1.1 使用kubeadm init 初始化master 节点使用kubeadm config print init-defaults可以打印集群初始化默认的使用的配置： 123456789101112131415161718192021222324252627282930313233343536373839================apiVersion: kubeadm.k8s.io/v1beta2bootstrapTokens:- groups:- system:bootstrappers:kubeadm:default-node-tokentoken: abcdef.0123456789abcdefttl: 24h0m0susages:- signing- authenticationkind: InitConfigurationlocalAPIEndpoint:advertiseAddress: 1.2.3.4bindPort: 6443nodeRegistration:criSocket: /var/run/dockershim.sockname: node1taints:- effect: NoSchedulekey: node-role.kubernetes.io/master---apiServer:timeoutForControlPlane: 4m0sapiVersion: kubeadm.k8s.io/v1beta2certificatesDir: /etc/kubernetes/pkiclusterName: kubernetescontrollerManager: &#123;&#125;dns:type: CoreDNSetcd:local:dataDir: /var/lib/etcdimageRepository: k8s.gcr.iokind: ClusterConfigurationkubernetesVersion: v1.16.0networking:dnsDomain: cluster.localserviceSubnet: 10.96.0.0/12scheduler: &#123;&#125; 从默认的配置中可以看到，可以使用imageRepository定制在集群初始化时拉取k8s所需镜像的地址。基于默认配置定制出本次使用kubeadm初始化集群所需的配置文件kubeadm.yaml：（注意修改advertiseAddress和kubernetsversion，nodesubet可以自己定义） 123456789101112131415apiVersion: kubeadm.k8s.io/v1beta2kind: InitConfigurationlocalAPIEndpoint:advertiseAddress: 172.18.10.18bindPort: 6443nodeRegistration:taints:- effect: PreferNoSchedulekey: node-role.kubernetes.io/master---apiVersion: kubeadm.k8s.io/v1beta2kind: ClusterConfigurationkubernetesVersion: v1.16.0networking:podSubnet: 10.244.0.0/16 使用kubeadm默认配置初始化的集群，会在master节点打上node-role.kubernetes.io/master:NoSchedule的污点，阻止master节点接受调度运行工作负载。这里测试环境只有两个节点，所以将这个taint修改为node-role.kubernetes.io/master:PreferNoSchedule，意思是pod会优先调度到普通节点，普通节点不够用master节点也可以运行业务pod。 参考： https://blog.frognew.com/2018/05/taint-and-toleration.html 在开始初始化集群之前可以使用kubeadm config images pull预先在各个节点上拉取所k8s需要的docker镜像。 接下来使用kubeadm初始化集群，选择node1作为Master Node，在node1上执行下面的命令： 1kubeadm init --config kubeadm.yaml --ignore-preflight-errors=Swap 执行成功后，会打印出这段说明： 1234567891011121314To start using your cluster, you need to run the following as a regular user:mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:kubeadm join 172.18.10.18:6443 --token ynmb9s.8darvwxj0y6klgj4 \\--discovery-token-ca-cert-hash sha256:345eeb7602eb6133ad032c8515f1d4a7a0d4180759893b32ddf1c043c9a73770 这里面提示要执行下面命令生成配置： 123mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config （只在master节点执行即可） 另外给了 普通node节点加入集群的命令： 12kubeadm join 172.18.10.18:6443 --token ynmb9s.8darvwxj0y6klgj4 \\--discovery-token-ca-cert-hash sha256:345eeb7602eb6133ad032c8515f1d4a7a0d4180759893b32ddf1c043c9a73770 查看一下集群状态，确认个组件都处于healthy状态： 1kubectl get cs 1234NAME STATUS MESSAGE ERRORcontroller-manager Healthy ok scheduler Healthy ok etcd-0 Healthy &#123;&quot;health&quot;:&quot;true&quot;&#125; 集群初始化如果遇到问题，可以使用下面的命令进行清理： 123456kubeadm resetifconfig cni0 downip link delete cni0ifconfig flannel.1 downip link delete flannel.1rm -rf /var/lib/cni/ 这些清理命令同样适用于从节点，清理需谨慎。 3.1.2 在主节点安装flannel network add-on 网络插件 1234mkdir -p ~/k8s/cd ~/k8scurl -O https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.ymlkubectl apply -f kube-flannel.yml 成功后打印： 123456789clusterrole.rbac.authorization.k8s.io/flannel createdclusterrolebinding.rbac.authorization.k8s.io/flannel createdserviceaccount/flannel createdconfigmap/kube-flannel-cfg createddaemonset.extensions/kube-flannel-ds-amd64 createddaemonset.extensions/kube-flannel-ds-arm64 createddaemonset.extensions/kube-flannel-ds-arm createddaemonset.extensions/kube-flannel-ds-ppc64le createddaemonset.extensions/kube-flannel-ds-s390x created 如果Node有多个网卡的话，参考lannel issues 39701，目前需要在kube-flannel.yml中使用–iface参数指定集群主机内网网卡的名称，否则可能会出现dns无法解析。需要将kube-flannel.yml下载到本地，flanneld启动参数加上–iface= 123456789containers: - name: kube-flannel image: quay.io/coreos/flannel:v0.11.0-amd64 command: - /opt/bin/flanneld args: - --ip-masq - --kube-subnet-mgr - --iface=eth1 使用kubectl get pod –all-namespaces -o wide确保所有的Pod都处于Running状态。 12345678910kubectl get pod -n kube-systemNAME READY STATUS RESTARTS AGEcoredns-5c98db65d4-dr8lf 1/1 Running 0 52mcoredns-5c98db65d4-lp8dg 1/1 Running 0 52metcd-node1 1/1 Running 0 51mkube-apiserver-node1 1/1 Running 0 51mkube-controller-manager-node1 1/1 Running 0 51mkube-flannel-ds-amd64-mm296 1/1 Running 0 44skube-proxy-kchkf 1/1 Running 0 52mkube-scheduler-node1 1/1 Running 0 51m 测试集群DNS是否可用 1kubectl run curl --image=radial/busyboxplus:curl -it 进入后执行nslookup kubernetes.default确认解析正常: nslookup kubernetes.default 3.2 将普通node节点加入集群很简单，只需要在普通node节点，执行上面给出的join命令即可（注意一定要参考2.7节关闭swap）： 12kubeadm join 172.18.10.18:6443 --token ynmb9s.8darvwxj0y6klgj4 \\--discovery-token-ca-cert-hash sha256:345eeb7602eb6133ad032c8515f1d4a7a0d4180759893b32ddf1c043c9a73770 在master节点通过kubectl get node 查看： 3.3 怎样从集群中移除node如果需要从集群中移除node2这个Node执行下面的命令： 在master节点上执行： 12kubectl drain node2 --delete-local-data --force --ignore-daemonsetskubectl delete node node2 在node2上执行： 123456kubeadm resetifconfig cni0 downip link delete cni0ifconfig flannel.1 downip link delete flannel.1rm -rf /var/lib/cni/ 在node1上执行： 1kubectl delete node node2 4 安装后配置4.1 kube-proxy开启ipvs在master节点，修改ConfigMap的kube-system/kube-proxy中的config.conf，mode: “ipvs” 1kubectl edit cm kube-proxy -n kube-system 之后重启各个节点上的kube-proxy pod，在master节点执行： 1kubectl get pod -n kube-system | grep kube-proxy | awk &#x27;&#123;system(&quot;kubectl delete pod &quot;$1&quot; -n kube-system&quot;)&#125;&#x27; 运行下面的命令检查一下： 1kubectl get pod -n kube-system | grep kube-proxy 日志中打印出了Using ipvs Proxier，说明ipvs模式已经开启 5 插件安装5.1 安装helmHelm是k8s 的包管理器，类似于yum和apt-get，有了helm后，安装k8s的一些插件会很容易。Helm由客户端命helm令行工具和服务端tiller组成。 1234curl -O https://get.helm.sh/helm-v2.14.1-linux-amd64.tar.gztar -zxvf helm-v2.14.1-linux-amd64.tar.gzcd linux-amd64/cp helm /usr/local/bin/ 因为Kubernetes APIServer开启了RBAC访问控制，所以需要创建tiller使用的service account: tiller并分配合适的角色给它。 详细内容可以查看helm文档中的Role-based Access Control。 这里简单起见直接分配cluster-admin这个集群内置的ClusterRole给它。创建helm-rbac.yaml文件： 123456789101112131415161718192021apiVersion: v1kind: ServiceAccountmetadata: name: tiller namespace: kube-system---apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: tillerroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects: - kind: ServiceAccount name: tiller namespace: kube-systemkubectl create -f helm-rbac.yamlserviceaccount/tiller createdclusterrolebinding.rbac.authorization.k8s.io/tiller created 接下来使用helm部署tiller: 1helm init --service-account tiller --output yaml | sed &#x27;s@apiVersion: extensions/v1beta1@apiVersion: apps/v1@&#x27; | sed &#x27;s@ replicas: 1@ replicas: 1\\n selector: &#123;&quot;matchLabels&quot;: &#123;&quot;app&quot;: &quot;helm&quot;, &quot;name&quot;: &quot;tiller&quot;&#125;&#125;@&#x27; | kubectl apply -f - tiller默认被部署在k8s集群中的kube-system这个namespace下： 123kubectl get pod -n kube-system -l app=helmNAME READY STATUS RESTARTS AGEtiller-deploy-c4fd4cd68-dwkhv 1/1 Running 0 83s helm version 12Client: &amp;version.Version&#123;SemVer:&quot;v2.14.1&quot;, GitCommit:&quot;5270352a09c7e8b6e8c9593002a73535276507c0&quot;, GitTreeState:&quot;clean&quot;&#125;Server: &amp;version.Version&#123;SemVer:&quot;v2.14.1&quot;, GitCommit:&quot;5270352a09c7e8b6e8c9593002a73535276507c0&quot;, GitTreeState:&quot;clean&quot;&#125; 为了拉取速度快些，可以在master节点上修改helm chart仓库的地址为azure提供的镜像地址： 12helmrepo add stable http://mirror.azure.cn/kubernetes/charts&quot;stable&quot; has been added to your repositories 1234helm repo listNAME URL stable http://mirror.azure.cn/kubernetes/chartslocal http://127.0.0.1:8879/charts 5.2 部署Nginx Ingress为了便于将集群中的服务暴露到集群外部，需要使用Ingress。 将master节点（node1）做为边缘节点，打上Label： 1kubectl label node node1 node-role.kubernetes.io/edge= stable/nginx-ingress chart的值文件ingress-nginx.yaml如下： 123456789101112131415161718192021222324252627282930313233343536controller: replicaCount: 1 hostNetwork: true nodeSelector: node-role.kubernetes.io/edge: &#x27;&#x27; affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: app operator: In values: - nginx-ingress - key: component operator: In values: - controller topologyKey: kubernetes.io/hostname tolerations: - key: node-role.kubernetes.io/master operator: Exists effect: NoSchedule - key: node-role.kubernetes.io/master operator: Exists effect: PreferNoScheduledefaultBackend: nodeSelector: node-role.kubernetes.io/edge: &#x27;&#x27; tolerations: - key: node-role.kubernetes.io/master operator: Exists effect: NoSchedule - key: node-role.kubernetes.io/master operator: Exists effect: PreferNoSchedule nginx ingress controller的副本数replicaCount为1，将被调度到node1这个边缘节点上。这里并没有指定nginx ingress controller service的externalIPs，而是通过hostNetwork: true设置nginx ingress controller使用宿主机网络。 1234567helm repo updatehelm install stable/nginx-ingress \\-n nginx-ingress \\--namespace ingress-nginx \\-f ingress-nginx.yaml 然后get pod查看下pod 状态 1kubectl get pod -n ingress-nginx -o wide pod状态为running后，可以在外面访问http://172.18.10.18返回default backend，则部署完成。5.3 安装k8s web ui （dashboard）我之前使用helm安装的dashboard 1.10版本，然后很多页面都报错404 not found，后面发现是因为安装的dashboard版本有点低，不适配1.16，安装最新的v2.0.0-beta4这个版本就可以完美适配 1.16 安装只需要执行： 1kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta4/aio/deploy/recommended.yaml 参考下面链接中说明 创建用户 获取token， 这个教程创建的用户有最高权限https://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/creating-sample-user.md Create Service AccountWe are creating Service Account with name admin-user in namespace kubernetes-dashboard first. 1234567891011121314151617181920apiVersion: v1kind: ServiceAccountmetadata: name: admin-user namespace: kubernetes-dashboardCreate ClusterRoleBindingIn most cases after provisioning our cluster using kops or kubeadm or any other popular tool, the ClusterRole admin-Role already exists in the cluster. We can use it and create only ClusterRoleBinding for our ServiceAccount.NOTE: apiVersion of ClusterRoleBinding resource may differ between Kubernetes versions. Prior to Kubernetes v1.8 the apiVersion was rbac.authorization.k8s.io/v1beta1.apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: admin-userroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: admin-user namespace: kubernetes-dashboard 获取token: 1kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk &#x27;&#123;print $1&#125;&#x27;) 通过ingress暴露服务： 12345678910111213141516171819202122apiVersion: extensions/v1beta1kind: Ingressmetadata:name: ingress-kube-dashboardannotations:# use the shared ingress-nginxkubernetes.io/ingress.class: &quot;nginx&quot;nginx.ingress.kubernetes.io/ssl-redirect: &quot;true&quot;nginx.ingress.kubernetes.io/backend-protocol: &quot;HTTPS&quot;spec:tls:- hosts:- k8s.redtea.comsecretName: redtea-com-tls-secretrules:- host: k8s.redtea.comhttp:paths:- path: /backend:serviceName: kubernetes-dashboardservicePort: 443 执行kubectl apply -f ingress-dashboard.yaml即可。 ingress用法参考： https://qhh.me/2019/08/12/%E4%BD%BF%E7%94%A8-Kubernetes-Ingress-%E5%AF%B9%E5%A4%96%E6%9A%B4%E9%9C%B2%E6%9C%8D%E5%8A%A1/ 后面就可以通过访问https://k8s.redtea.com通过GUI 查看和管理集群。 6 一些注意点1. kube-proxy开启ipvs 需要加载一些内核模块，在5.3.7的内核版本，nf_conntrack_ipv4被nf_contrack代替，所以使用下面的命令：123456789cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF#!/bin/bashmodprobe -- ip_vsmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- ip_vs_shmodprobe -- nf_conntrackEOFchmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep -e ip_vs -e nf_conntrack 2. 从节点在加入主节点之前，必须按照2.7 中的说明，把swap关掉3. 3.1.2安装Pod network配置flannel 应该只需要在主节点执行，从节点不需要4. helm安装tiller报错 no resource found，可以参考该文章解决： init –service-account tiller –output yaml | sed ‘s@apiVersion: extensions/v1beta1@apiVersion: apps/v1@’ | sed ‘s@ replicas: 1@ replicas: 1\\n selector: {“matchLabels”: {“app”: “helm”, “name”: “tiller”}}@’ | kubectl apply -f -5. 主节点 kubeadm init完成后，务必按照提示，创建配置目录：mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 6. 为了使dashboard能正常显示监控数据，可以安装heapster：参考：https://blog.csdn.net/qianghaohao/article/details/98859392 一些机器原始设置备份：/etc/default/grub 原始配置备份： 1234567GRUB_TIMEOUT=5GRUB_DISTRIBUTOR=&quot;$(sed &#x27;s, release .*$,,g&#x27; /etc/system-release)&quot;GRUB_DEFAULT=savedGRUB_DISABLE_SUBMENU=trueGRUB_TERMINAL_OUTPUT=&quot;console&quot;GRUB_CMDLINE_LINUX=&quot;crashkernel=auto rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet&quot;GRUB_DISABLE_RECOVERY=&quot;true&quot; 其他： 关于ingress ngnix https://qhh.me/2019/08/12/%E4%BD%BF%E7%94%A8-Kubernetes-Ingress-%E5%AF%B9%E5%A4%96%E6%9A%B4%E9%9C%B2%E6%9C%8D%E5%8A%A1/ 获取dashboard登录token：kubectl -n kube-system get secret | grep kubernetes-dashboard-tokenkubernetes-dashboard-token-xmzngkubectl describe -n kube-system secret/kubernetes-dashboard-token-xmzng kubectl config set-context kubernetes-dashboard@kubernetes –cluster=kubernetes –user=kubernetes-dashboard –kubeconfig=/root/dashbord-admin.confkubectl config user-context kubernetes-dashboard@kubernets –kubeconfig=/root/dashbord-admin.conf 上面搭的集群不具备高可用的特性，只有一个master节点，一旦该master挂掉，集群就无法管理了关于高可用k8s集群：https://blog.csdn.net/networken/article/details/89599004https://blog.csdn.net/fanren224/article/details/86573264https://blog.51cto.com/billy98/2350660https://www.jianshu.com/p/8eb81d1674dchttps://www.kubernetes.org.cn/5273.html 参考：使用kubeadm部署k8s集群： https://www.kubernetes.org.cn/5551.htmlhttps://www.kubernetes.org.cn/5551.html","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"关于Redis分布式锁以及Redisson的用法","slug":"distribute_lock_redisson","date":"2020-02-01T05:32:33.000Z","updated":"2021-06-21T06:38:19.294Z","comments":true,"path":"2020/02/01/distribute_lock_redisson/","link":"","permalink":"http://example.com/2020/02/01/distribute_lock_redisson/","excerpt":"Redis分布式锁思路一般是通过setnx命令，该命令含义为set if not exist，也就是key不存在则设值，存在则不作任何处理，返回值为： 1 key 不存在，被成功设值 0 key 已存在，设值失败，不作处理 通过判断setnx的返回值，如果是0，说明已经其他线程加锁成功，需要等待，如果是1，则本线程加锁成功，进入临界区访问资源，并设值key的有效时间，防止key一直不释放，造成死锁。 由于setnx的特性，等待锁的线程可以一直循环执行该命令检测锁的状态。","text":"Redis分布式锁思路一般是通过setnx命令，该命令含义为set if not exist，也就是key不存在则设值，存在则不作任何处理，返回值为： 1 key 不存在，被成功设值 0 key 已存在，设值失败，不作处理 通过判断setnx的返回值，如果是0，说明已经其他线程加锁成功，需要等待，如果是1，则本线程加锁成功，进入临界区访问资源，并设值key的有效时间，防止key一直不释放，造成死锁。 由于setnx的特性，等待锁的线程可以一直循环执行该命令检测锁的状态。 1 Redis分布式锁的错误示范1234# 伪代码result = jedis.setnx(&quot;lock_key&quot;, &quot;current_timestamp&quot;);if result:jedis.expire(&quot;lock_key&quot;, 30); 问题1：setnx和expire不是原子操作，如果setnx后出现异常，expire一直没执行，key就一直不会释放，造成死锁。 问题2：对value没有检查，可能会导致别的线程解锁当前线程设置的锁。 对于原子性问题，可以在新版本redis使用set命令，set(key,value,option,expiretime), 一条命令可以实现setnx的同时设置expiretime 对于 value问题，可以将value设置为当前加锁对象的标识，在解锁时判断value与自身标识是否一致。但是这里涉及到一个getvalue和deletekey双重操作，必须要保证原子性, 否则getvalue比较后，出现异常，delete操作就不会执行，锁也一直无法释放，考虑使用lua脚本来做： 12345678910/** * 释放分布式锁 * @param key * @param uniqueId */public static boolean releaseLock(String key, String uniqueId) &#123; String luaScript = &quot;if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1] then &quot; + &quot;return redis.call(&#x27;del&#x27;, KEYS[1]) else return 0 end&quot;; return jedis.eval(luaScript, Collections.singletonList(key), Collections.singletonList(uniqueId)).equals(1L);&#125; 2 Redisson的用法github: https://github.com/redisson/redisson maven: 12345&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.11.1&lt;/version&gt;&lt;/dependency&gt; 2.1 单机模式： 1234567@Bean public RedissonClient redissonClient() &#123; Config config = new Config(); config.useClusterServers().addNodeAddress(&quot;redis://&quot; + host + &quot;:&quot; + port).setScanInterval(5000); return Redisson.create(config); &#125; 2.2 cluster模式： 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.redteamobile.stat.configuration;import lombok.Data;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.stereotype.Component;@Component@ConfigurationProperties(prefix = &quot;spring.redis.cluster&quot;)@Datapublic class RedisClusterProperties &#123; private String nodes; private Integer commandTimeout; private Integer maxAttempts; private Integer maxRedirects; private Integer maxActive; private Integer maxWait; private Integer maxIdle; private Integer minIdle; private boolean testOnBorrow;&#125;@Bean public RedissonClient redissonClient() &#123; Config config = new Config(); String[] cNodes = redisClusterProperties.getNodes().split(&quot;,&quot;); List&lt;String&gt; nodes = Arrays.asList(cNodes).stream().map(cNode -&gt; &quot;redis://&quot; + cNode).collect(Collectors.toList()); config.useClusterServers().addNodeAddress(nodes.toArray(new String[nodes.size()])).setScanInterval(5000); return Redisson.create(config); &#125; 123456789101112131415161718192021 redis:# cluster:# # 各 Redis 节点信息 192.168.117.135:6379,192.168.117.135:6380,192.168.117.136:7379,192.168.117.136:7380,192.168.117.137:8379,192.168.117.137:8380# nodes: 10.244.1.3:6379,10.244.2.3:6379,10.244.0.7:6379,10.244.2.4:6379,10.244.1.5:6379,10.244.1.6:6379# # 执行命令超时时间# command-timeout: 15000# # 重试次数# max-attempts: 5# # 跨集群执行命令时要遵循的最大重定向数量# max-redirects: 3# # 连接池最大连接数（使用负值表示没有限制）# max-active: 16# # 连接池最大阻塞等待时间（使用负值表示没有限制）# max-wait: -1# # 连接池中的最大空闲连接# max-idle: 8# # 连接池中的最小空闲连接# min-idle: 0# # 是否在从池中取出连接前进行检验,如果检验失败,则从池中去除连接并尝试取出另一个# test-on-borrow: true 2.3 哨兵模式： 12345Config config = new Config();config.useSentinelServers().addSentinelAddress( &quot;redis://172.29.3.245:26378&quot;,&quot;redis://172.29.3.245:26379&quot;, &quot;redis://172.29.3.245:26380&quot;) .setMasterName(&quot;mymaster&quot;) .setPassword(&quot;a123456&quot;).setDatabase(0); 2.4 RedLock 注意上面三种都是针对同一个redis集群的，如果有大型系统使用多个redis集群（注意是多个集群，不是多个实例），要获取多集群redis分布式锁，可以考虑使用Redlock(假设每个集群只有一个redis实例)： 1234567891011121314151617181920212223242526272829303132333435Config config1 = new Config();config1.useSingleServer().setAddress(&quot;redis://172.29.1.180:5378&quot;) .setPassword(&quot;a123456&quot;).setDatabase(0);RedissonClient redissonClient1 = Redisson.create(config1);Config config2 = new Config();config2.useSingleServer().setAddress(&quot;redis://172.29.1.180:5379&quot;) .setPassword(&quot;a123456&quot;).setDatabase(0);RedissonClient redissonClient2 = Redisson.create(config2);Config config3 = new Config();config3.useSingleServer().setAddress(&quot;redis://172.29.1.180:5380&quot;) .setPassword(&quot;a123456&quot;).setDatabase(0);RedissonClient redissonClient3 = Redisson.create(config3);String resourceName = &quot;REDLOCK&quot;;RLock lock1 = redissonClient1.getLock(resourceName);RLock lock2 = redissonClient2.getLock(resourceName);RLock lock3 = redissonClient3.getLock(resourceName);RedissonRedLock redLock = new RedissonRedLock(lock1, lock2, lock3);boolean isLock;try &#123; isLock = redLock.tryLock(500, 30000, TimeUnit.MILLISECONDS); System.out.println(&quot;isLock = &quot;+isLock); if (isLock) &#123; //TODO if get lock success, do something; Thread.sleep(30000); &#125;&#125; catch (Exception e) &#123;&#125; finally &#123; // 无论如何, 最后都要解锁 System.out.println(&quot;&quot;); redLock.unlock();&#125; 可以看到Redlock RedissonRedLock redLock = new RedissonRedLock(lock1, lock2, lock3); 2.5 获取锁： 12345678910111213141516171819202122RLock lock = redissonClient.getLock(LOCK_NAME); try &#123; boolean isLock = lock.tryLock(LOCK_ACQUIRE_TIME_OUT_IN_SECONDS, TimeUnit.SECONDS); if (!isLock) &#123; logger.warn(&quot;get distribute lock failed&quot;); return; &#125; // do something &#125; catch (Exception e) &#123; logger.error(&quot;collect stat data failed&quot;, e); &#125; finally &#123; lock.unlock(); &#125; redisson RLOCK接口方法说明： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public interface RRLock &#123; //----------------------Lock接口方法----------------------- /** * 加锁 锁的有效期默认30秒 */ void lock(); /** * tryLock()方法是有返回值的，它表示用来尝试获取锁，如果获取成功，则返回true，如果获取失败（即锁已被其他线程获取），则返回false . */ boolean tryLock(); /** * tryLock(long time, TimeUnit unit)方法和tryLock()方法是类似的，只不过区别在于这个方法在拿不到锁时会等待一定的时间， * 在时间期限之内如果还拿不到锁，就返回false。如果如果一开始拿到锁或者在等待期间内拿到了锁，则返回true。 * * @param time 等待时间 * @param unit 时间单位 小时、分、秒、毫秒等 */ boolean tryLock(long time, TimeUnit unit) throws InterruptedException; /** * 解锁 */ void unlock(); /** * 中断锁 表示该锁可以被中断 假如A和B同时调这个方法，A获取锁，B为获取锁，那么B线程可以通过 * Thread.currentThread().interrupt(); 方法真正中断该线程 */ void lockInterruptibly(); //----------------------RLock接口方法----------------------- /** * 加锁 上面是默认30秒这里可以手动设置锁的有效时间 * * @param leaseTime 锁有效时间 * @param unit 时间单位 小时、分、秒、毫秒等 */ void lock(long leaseTime, TimeUnit unit); /** * 这里比上面多一个参数，多添加一个锁的有效时间 * * @param waitTime 等待时间 * @param leaseTime 锁有效时间 * @param unit 时间单位 小时、分、秒、毫秒等 */ boolean tryLock(long waitTime, long leaseTime, TimeUnit unit) throws InterruptedException; /** * 检验该锁是否被线程使用，如果被使用返回True */ boolean isLocked(); /** * 检查当前线程是否获得此锁（这个和上面的区别就是该方法可以判断是否当前线程获得此锁，而不是此锁是否被线程占有） * 这个比上面那个实用 */ boolean isHeldByCurrentThread(); /** * 中断锁 和上面中断锁差不多，只是这里如果获得锁成功,添加锁的有效时间 * @param leaseTime 锁有效时间 * @param unit 时间单位 小时、分、秒、毫秒等 */ void lockInterruptibly(long leaseTime, TimeUnit unit); &#125; 参考： Redisson实现Redis分布式锁的N种姿势 Redisson基本用法 Redisson实现分布式锁(2)—RedissonLock","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"使用redistemplate调用lua脚本实现的redis计数器","slug":"redis_lua_counter","date":"2020-02-01T05:30:33.000Z","updated":"2021-06-21T06:38:19.765Z","comments":true,"path":"2020/02/01/redis_lua_counter/","link":"","permalink":"http://example.com/2020/02/01/redis_lua_counter/","excerpt":"","text":"redistemplate执行lua脚本的方式12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.redteamobile.stat.redis;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.core.script.DefaultRedisScript;import org.springframework.scripting.support.StaticScriptSource;import org.springframework.stereotype.Repository;import javax.annotation.Resource;import java.util.Arrays;/** * @ClassName RedisCounter * @Description TODO * @Author zijian zhao * @Date 2020/1/14 11:48 */@Repositorypublic class RedisCounter &#123; private Logger logger = LoggerFactory.getLogger(getClass()); @Resource(name = &quot;redisTemplate&quot;) private RedisTemplate redisTemplate; public static final Integer DEFAULT_EXPIRE_TIME_IN_SECONDS = 60 * 60 * 2; public static final String LUA_INCR_EXPIRE_ATOMIC_SCRIPT = &quot;local current = redis.call(&#x27;incrBy&#x27;,KEYS[1],ARGV[1]);&quot; + &quot; if current == tonumber(ARGV[1]) then&quot; + &quot; local t = redis.call(&#x27;ttl&#x27;,KEYS[1]);&quot; + &quot; if t == -1 then &quot; + &quot; redis.call(&#x27;expire&#x27;,KEYS[1],ARGV[2])&quot; + &quot; end;&quot; + &quot; end;&quot; + &quot; return current&quot;; /** * Redis计数器 使用lua脚本保证incr操作和expire操作的原子性 * @param key 键值对key * @param step 步长 * @param defaultExpire 失效时间 * @return count */ public Long incrBy(final String key, final Integer step, final Integer defaultExpire) &#123; try &#123; DefaultRedisScript&lt;Long&gt; script = new DefaultRedisScript&lt;Long&gt;(); script.setResultType(Long.class); script.setScriptSource(new StaticScriptSource(LUA_INCR_EXPIRE_ATOMIC_SCRIPT)); return (Long) redisTemplate.execute(script, Arrays.asList(key), step, defaultExpire); &#125; catch (Exception e) &#123; logger.error(&quot;redis counter incr failed&quot;, e); return null; &#125; &#125;&#125; 在redis中使用lua脚本的命令格式1eval lua-script key-num [key1 key2 key3 ....] [value1 value2 value3 ....] eval 是redis提供的执行lua脚本的命令 lua-script为字符串形式lua脚本 key-num标识后面key列表里key的个数，如果没有key，写0，该参数是用来区分后面的key和value的。 key 列表，会作为参数传递给lua脚本，需要和key-num数量保持一致 value 列表，也是作为参数传递给lua脚本 1eval &quot;redis.call(&#x27;set&#x27;,KEYS[1],ARGV[1])&quot; 1 lua-key lua-value 在lua脚本里，使用KEYS[index] 来获取 eval命令中的 key列表参数， 使用ARGV[INDEX]获取eval命令中的value列表参数。注意这里的index都是从1开始的。 lua中调用redis命令的语法为 1redis.call(&#x27;command_name&#x27;, [param1, param2,]) 实际行lua脚本中执行redis命令还有一个redis.pcall()命令，两者的区别在于redis.call执行出错会直接raise错误，脚本停止执行，redis.pcall则不会raise错误，返回一个lua的table对象指示错误。 关于evalsha命令: evalsha和eval都可以用来执行lua脚本，区别在于eval执行的是原始的lua脚本，而evalsha为sha-1签名过的lua脚本，用法为首先用该命令给指定lua脚本生成一个sha-1签名： 12# 将一个脚本装入脚本缓存，但并不立即运行它script load lua-script 得到返回的签名后，就可以用evalsha 加该签名来执行lua脚本，优点在于 如果有些脚本很长，且频繁要被执行，每次传输原始脚本效率不高，而sha-1后的签名会缓存在redis服务端，后续只需要传一个32位的sha-1签名，提高传输效率和性能 刷新脚本缓存是显式地调用 SCRIPT FLUSH 命令，会清空运行过的所有脚本的缓存 参考： EVAL script numkeys key [key …] arg [arg …]","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"说说加密算法","slug":"encrypt_alg","date":"2020-02-01T05:28:33.000Z","updated":"2021-06-21T06:38:19.394Z","comments":true,"path":"2020/02/01/encrypt_alg/","link":"","permalink":"http://example.com/2020/02/01/encrypt_alg/","excerpt":"","text":"MD5 SHA-1 SHA-2 SHA-3这些都属于hash算法，特点都是可以将任意文本（不太严谨，最大还是有长度限制的，比如SHA-1最大为2的64次方位）转换为一个固定长度的字符串，SHA-1比如固定为160位。不同的源字符串，最后生成的签名都不一样（理论上，实际上有hash碰撞，只是概率极小，需要极大的算力），所以可以使用hash摘要算法来校验原始文本或文件的完整性。 SHA-1 是摘要算法的一种，目前已经不再安全，有充足计算资源的攻击者可以暴力破解，它签名的结果为160个比特位，除以8对应20个字节，通常我们表示的时候表示为16进制数，160除以4，表示为40位16进制字符串。 MD5 签名结果为128个比特位，16字节， 32个16进制数字。 SHA-2 表示了一组hash算法，包括SHA-224、SHA-256、SHA-384、SHA-512、SHA-512/224、SHA-512/256后面的数字表示了散列结果的位数，位数越多，发生hhash碰撞的概率就越低，就更安全。SHA-256 SHA-512是常用的摘要算法。 SHA-3 是第三代hash算法，使用Keccak算法。SHA3-224 SHA3-256 SHA3-384 SHA3-512 MD5和SHA-0 SHA-1目前都是不安全，不推荐的摘要算法。","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"电信领域几个名词的理解(IMSI ICCID IMEI)","slug":"imsi_iccid_imei","date":"2020-02-01T05:24:33.000Z","updated":"2021-06-21T06:38:19.432Z","comments":true,"path":"2020/02/01/imsi_iccid_imei/","link":"","permalink":"http://example.com/2020/02/01/imsi_iccid_imei/","excerpt":"","text":"IMSI： 移动用户唯一识别码，存在SIM卡里，是用户的标识，IMSI会和KI一起去运营商网络里做认证，认证通过后即可上网。 ICCID： ICCID 集成电路卡识别码，存在SIM卡里，是卡的标识，或者叫序列号， ICCID和IMSI可以类比为，ICCID相当于身份证卡片的序列号，换身份证后，卡序列号可能会变，但是IMSI相当于一个人的身份证号，不论怎么换卡，身份证号都不会变。ICCID只是用来区别SIM卡，不作接入网络的鉴权认证，可以伪造，可以用一张空白多号卡，写入IMSI和KI，只要是经过破解的IMSI和KI，就可以接入网络，而ICCID可以任意20位数字。实际上，软SIM，就是可以通过以软件方式实现IMSI+KI去认证，有多个IMSI+KI就可以实现一卡多号的能力。默认20位。 IMEI：移动设备识别码，是硬件设备，如手机，的硬件设备唯一识别码，IMEI从生产厂商到零售用户一套生产线都会被记录。默认15位。 ps：对于iphone： iPhone在激活的时候，会把ICCID和IMSI一起发送到苹果服务器端进行验证。特别是有锁的手机，就使用IMSI来判断是否合法运营商，如果不合法，就无法激活。ICCID作为SIM卡标识，在激活的时候被记录下来，直到下次刷机，在服务端的记录都不会被改变 ps: IMEI现在绝大部分都是英国的授权机构BABT分配的，有意思的是维基百科里有这么一段： 由于中国制造的手机以低廉价格威胁到了欧洲国际大厂的生存，现在欧洲对中国产手机的IMEI收费从原来的免费到每个机型2000美金","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"Kubernetes中的计量单位","slug":"k8s_meter_unit","date":"2020-02-01T05:24:33.000Z","updated":"2021-06-21T06:38:19.610Z","comments":true,"path":"2020/02/01/k8s_meter_unit/","link":"","permalink":"http://example.com/2020/02/01/k8s_meter_unit/","excerpt":"","text":"CPU 计量CPU 资源的限制和请求以 cpu 为单位。 Kubernetes 中的一个 cpu 等于： 1 AWS vCPU1 GCP Core1 Azure vCore1 Hyperthread 在带有超线程的裸机 Intel 处理器上 CPU 总是要用绝对数量，不可以使用相对数量；0.1 的 CPU 在单核、双核、48核的机器中的意义是一样的 实际使用中，使用m标识一千分之一的cpu，即millicpu，如1000m相当于1cpu，100m相当于0.1cpu。 内存计量十进制单位： E，P，T，G，M，K二进制单位： Ei，Pi，Ti ，Gi，Mi，Ki 举例M和Mi的区别在于，1M 相当于 1000 * 1000 bytes1Mi相当于 1024 * 1024 bytes","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"Mybatis批量insert数据的写法","slug":"mybatis_batch_oper","date":"2020-02-01T05:24:33.000Z","updated":"2021-06-21T06:38:19.679Z","comments":true,"path":"2020/02/01/mybatis_batch_oper/","link":"","permalink":"http://example.com/2020/02/01/mybatis_batch_oper/","excerpt":"","text":"XML文件1234567&lt;insert id=&quot;batchInsertStatMins&quot;&gt; INSERT INTO stat_min(measure_type,collect_time,value,description) VALUES &lt;foreach collection=&quot;statMins&quot; item=&quot;min&quot; separator=&quot;,&quot;&gt; (#&#123;min.measureType&#125;,#&#123;min.collectTime&#125;,#&#123;min.value&#125;,#&#123;min.description&#125;) &lt;/foreach&gt; &lt;/insert&gt; 关于foreach： collection：指定要遍历的集合，对应mapper中传入的collection类型的参数名称 list类型的参数会特殊处理封装在map中，map的key就叫list item：将当前遍历出的元素赋值给指定的变量 separator:每个元素之间的分隔符 open：遍历出所有结果拼接一个开始的字符 close:遍历出所有结果拼接一个结束的字符 index:索引。遍历list的时候是index就是索引，item就是当前值，遍历map的时候index表示的就是map的key，item就是map的值 #{变量名} Mapper123456@Mapperpublic interface StatDao &#123; int batchInsertStatMins(@Param(&quot;statMins&quot;) List&lt;StatMin&gt; statMins);&#125; 返回insert成功的行数 关于返回值insert update delete 默认返回都是受影响的行数。 有些文章里说的，insert单条语句返回值是null的说法是不对的，另外，insert操作加来指明返回的主键值有待验证。","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"不可能完成的年度计划之2020篇","slug":"2020","date":"2020-01-01T11:46:38.000Z","updated":"2021-06-21T06:38:18.759Z","comments":true,"path":"2020/01/01/2020/","link":"","permalink":"http://example.com/2020/01/01/2020/","excerpt":"","text":"生活上： 多喝水 不要一直盯着电脑 适度休息眼睛 每周给家里打电话 条件允许的情况 不要熬夜 减少不必要的消费 个人成长： 每周写两篇技术博客 摄影 后期 PS 调色 素描或水彩画 能在全年都为面试做好准备 旅行： 重庆和云南 今年的目标就很简单和粗暴，就是实现财务自由，earn more money。 so，move on，用1000个小时专注一件事，成为专家。 2020的slogan是： 做个行动派 更果敢","categories":[{"name":"Emotion","slug":"Emotion","permalink":"http://example.com/categories/Emotion/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"对CI CD 微服务的一些理解","slug":"CI_CD_microservice","date":"2019-10-20T04:54:33.000Z","updated":"2021-06-21T06:38:18.936Z","comments":true,"path":"2019/10/20/CI_CD_microservice/","link":"","permalink":"http://example.com/2019/10/20/CI_CD_microservice/","excerpt":"CI CD Devops是敏捷开发模式的几个概念，实现的核心都是自动化技术。CI 就是持续集成，即将代码入库后，工具监测到变更，自动触发的构建，执行单元测试等一系列工作，目的就是能够将最新的变更频繁有效的合入主干，保证合入质量的方式包括持续集成前的代码检视，如gerrit工具，还有持续集成过程中的构建和自动执行单元测试。持续集成的好处在于 本地的需求变更能够更快速的反映到主干，适应快速迭代的开发节奏，这样可以更快更早的发现错误及时应对，也防止分支代码大量偏离主干。","text":"CI CD Devops是敏捷开发模式的几个概念，实现的核心都是自动化技术。CI 就是持续集成，即将代码入库后，工具监测到变更，自动触发的构建，执行单元测试等一系列工作，目的就是能够将最新的变更频繁有效的合入主干，保证合入质量的方式包括持续集成前的代码检视，如gerrit工具，还有持续集成过程中的构建和自动执行单元测试。持续集成的好处在于 本地的需求变更能够更快速的反映到主干，适应快速迭代的开发节奏，这样可以更快更早的发现错误及时应对，也防止分支代码大量偏离主干。 CD 有两个概念，一个是持续部署（Continuous Deployment），一个是持续交付（Continuous Delivery）。 持续部署就是通过自动化工具，能够将CI集成出的可用软件包版本快速部署到测试和生产环境上，提供给client使用； 持续交付则是持续集成+持续测试+持续部署一整套管道。持续交付强调的是，不管怎么更新，软件都是随时可以交付的。 DevOps 来自于Development和Operations的组合，突出开发和运维的沟通合作，通过自动化流程来使得软件构建、测试、发布更加快捷、频繁和可靠。DevOps可以认为是一个指导敏捷开发的开发理念，它基于CI CD这些基础能力。 微服务架构的几个特点： 跑在自己的进程里 分布式部署 语言无关性 解构，独立开发 独立部署 有独立的开发 集成 部署周期","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"关于load average 指标","slug":"loadaverage","date":"2019-10-19T08:54:33.000Z","updated":"2021-06-21T06:38:19.633Z","comments":true,"path":"2019/10/19/loadaverage/","link":"","permalink":"http://example.com/2019/10/19/loadaverage/","excerpt":"","text":"被人问到top等命令显示的load average 指标，自己在系统和JVM监控方面还有很多知识盲区，故总结如下。 如何查看load average？ uptime top w load average 表示什么？怎样计算的？load average 显示为： load average: 0.40, 0.58, 0.27 load average 表示 正在运行的进程 + 准备好等待运行的进程在特定时间内（1分钟，5分钟，10分钟）的平均进程数（比如现在系统有2个正在运行的进程，3个可运行进程，那么系统的load就是5）。这里的平均是说系统每5s采样一次（Linux），在1分钟/5分钟/10分钟内采样数据的平均值，它统计的是正在运行和进入就绪状态的进程，不包括等待IO、处于wait、被kill的进程，换句话说，是当前所有竞争cpu时间片的进程。 需要注意的是，这个值它计算的时候没有考虑到cpu核心数，一般来说，多核cpu在看load average的时候，需要用显示的值除以cpu核心数，才能得到有意义的参考值。 使用如下命令查看cpu核心数： cat /proc/cpuinfo |grep &quot;cores&quot;|uniq 怎样是安全的load average？一般来说，这个值保持在0.7以下是理想状态，在0.7~1之间虽然暂时看没有问题，但是建议先行分析找出隐患，如果在5以上就说明在超负荷运转了，需要立即排查问题。","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"JAVA中的阻塞队列","slug":"JAVA_blockingqueue","date":"2019-10-18T09:54:33.000Z","updated":"2021-06-21T06:38:19.574Z","comments":true,"path":"2019/10/18/JAVA_blockingqueue/","link":"","permalink":"http://example.com/2019/10/18/JAVA_blockingqueue/","excerpt":"","text":"继承关系BlockingQueue(interface)—–&gt;Queue(interface)—–&gt;Collection(interface) BlockingQueue接口提供的方法可以分为三类： add remove element 这三个方法的特点是如果操作不成功直接抛出异常 offer poll peek 这三个方法的特点是操作不成功不会抛异常，而是返回一个操作成功或失败的结果 put take 是两个阻塞方法，即操作会一直阻塞，指导成功，比如队列已满进行put操作就会一直等待不会返回 备注： offer和poll 有两个重载的带超时参数的方法，也会阻塞，知道达到超时时间。 remove poll take 都会移除队列中的元素，并返回该元素 不能向BlockingQueue插入一个空对象，否则会抛出NullPointerException JDK提供的常见阻塞队列 ArrayBlockingQueue FIFO 数组实现的有界阻塞队列，初始化时必须指定长度 LinkedBlockingQueue FIFO 链表实现的无界阻塞队列，也不是真的无界，初始化时不指定长度则默认为Integer.MAX_VALUE PriorityBlockingQueue 不遵循FIFO，而是提供了方法可以按照优先级出队，是一个基于数组的无界队列，插入的元素必须指定Comparator。 DelayQueue、BlockingDeque 双端队列，可以从任意一端插入或者抽取元素，最大长度Integer.MAX_VALUE SynchronousQueue","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"Spring拾遗","slug":"Spring_basic","date":"2019-09-18T02:09:33.000Z","updated":"2021-06-21T06:38:19.820Z","comments":true,"path":"2019/09/18/Spring_basic/","link":"","permalink":"http://example.com/2019/09/18/Spring_basic/","excerpt":"spring俨然是java后端框架的基础设施，遗憾的是一直没研究过源码，只停留在使用层面。DI和AOP的原理就不多说了，围绕spring的一些细节，做个总结。 1 Spring 事务Spring事务管理 Spring Boot中的事务管理 网上这两个文章总结的很全面，记录一下比较重要的几个点。 并发事务操作相同数据引起的三个问题：脏读，不可重复读，幻读。 脏读是一个事务在另一个事务操作未提交的情况下对相同数据进行读取，另一个事务操作完成后，导致第一个事务读取无效。 而不可重复读是指读取多次数据，在两次读取的间隔中，有可能其他事务对数据进行了操作，导致多次读取相同数据的结果不一致。幻读，则是指多次重复读取时，记录条数不一致。 不可重复读和幻读的区别就在于，前者是同一条记录的某些字段可能不一致，后者是表记录的数量可能不一致，也就是他们锁定的粒度不同。前者粒度小，后者粒度打，为了防止幻读，一般是通过锁定整张表来实现，这样会严重影响性能。","text":"spring俨然是java后端框架的基础设施，遗憾的是一直没研究过源码，只停留在使用层面。DI和AOP的原理就不多说了，围绕spring的一些细节，做个总结。 1 Spring 事务Spring事务管理 Spring Boot中的事务管理 网上这两个文章总结的很全面，记录一下比较重要的几个点。 并发事务操作相同数据引起的三个问题：脏读，不可重复读，幻读。 脏读是一个事务在另一个事务操作未提交的情况下对相同数据进行读取，另一个事务操作完成后，导致第一个事务读取无效。 而不可重复读是指读取多次数据，在两次读取的间隔中，有可能其他事务对数据进行了操作，导致多次读取相同数据的结果不一致。幻读，则是指多次重复读取时，记录条数不一致。 不可重复读和幻读的区别就在于，前者是同一条记录的某些字段可能不一致，后者是表记录的数量可能不一致，也就是他们锁定的粒度不同。前者粒度小，后者粒度打，为了防止幻读，一般是通过锁定整张表来实现，这样会严重影响性能。 Spring并不直接管理事务，而是提供了统一接口org.springframework.transaction.PlatformTransactionManager，将事务管理的职责委托给Hibernate或者JTA等持久化机制所提供的相关平台框架的事务来实现，比如JDBC事务，hibernate事务，JPA事务,JTA事务。默认情况下，数据库持久化操作是自动提交的，事务的概念其实我理解相当于把autocommit设为false，在一系列操作后和发生异常后，通过事务管理器手动去commit和rollback，基于此，其实不适用spring的事务，我们自己通过jdbc等持久化依赖提供的方法也可以自己实现事务管理，只是说spring事务时现成的轮子，我们直接拿来用而已。 关于隔离级别。5中隔离级别中，default是使用后端数据库默认的隔离级别，大多数情况，这个值等于READ_COMMITTED；READ_COMMITTED是大多数情况采用的，能阻止脏读，但是不能避免不可重复读和幻读，它只允许读取其他事务已经提交的数据。READ_UNCOMMITTED是最低的隔离级别，三个问题都无法避免。 SERIALIZABLE是最高的隔离级别，能避免三个问题，但是性能极差。 事务分为两种，编程式事务和声明式事务，编程式事务是手动初始化一个dataSourceTransactionManager，并自己写try catch，调用dataSourceTransactionManager的rollback和commit方法来实现的，这种方式可以个性化控制事务的粒度和逻辑，但是这导致事务和业务代码耦合在一起。 而声明式事务是通过AOP方式实现，对业务代码没有侵入，低耦合。 声明式事务的使用方式。xml配置的话需要先用&lt;tx:annotation-driven transaction-manager=”transactionManager”/&gt;开启事务，然后配置transactionmanager的bean。注解形式，在@Configuration中用@EnableTransactionManagement开启事务，在@Configuration中可以用@Bean定义需要初始化的transactionmanager。最后使用时在需要纳入事务管理的类或方法上通过@transactional注解来标注一个声明式事务(标注在类上，则说明类中所有方法纳入事务管理)。 事务的传播行为（propagation behavior）。传播行为指的时，如果两个方法都用@transactional标注成事务方法，那一个调用另一个时事务的处理方式。其中最常用的required，表示当前方法必须运行在事务中。如果当前事务存在，方法将会在该事务中运行。否则，会启动一个新的事务，required和required_new的区别在于，required被调用方法会纳入调用方法的事务中，而required_new的被调用方法是一个独立的事务，也就是不属于外层的事务，内层事务执行完就会提交。 在Spring Boot中，当引入了spring-boot-starter-jdbc或spring-boot-starter-data-jpa依赖，框 架会自动默认分别注入DataSourceTransactionManager或JpaTransactionManager。在springapplication入口类上用@EnableTransactionManagement 开启事务支持，就可以用@Transactional注解进行事务的使用。需要注意的时，当引入的持久化依赖有多个时，有两种处理方式，一个是用@bean手动注入一个需要使用的事务管理器，因为@bean注如的bean会被优先加载，外部依赖中的事务管理器就不会再被加载了。另一个方式是用@transactional注解时，用value指定需要使用的事务管理器的名称。 2 关于AOP spring AOP 是基于动态代理的，实现有两个，一个是JDK自带的动态代理，另一个Cglib。 两个的区别在于，JDK动态代理必须基于接口，通过反射来实现，通过JDK提供的lang.reflect.Proxy.newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h)来生成代理类，第一个参数为被代理的类的class，第二个参数为被代理类实现的接口，最后一个参数为InvocationHandler接口的实现类，在该接口的invoke方法中定义自定义的增强功能。 第二个动态代理的实现方式为Cglib，它是通过在底层获取到被代理类的class，通过修改字节码，生成被代理类的子类来实现功能增强的，不需要实现接口，所以泛用性更高。基于这两种实现方式，那可以得出结论，就是目标类没有实现接口，且class为final修饰时，是无法使用Srping AOP的，因为没有实现接口就不能使用JDK动态代理，而class为final意味着无法被继承，也就无法生成子类，Cglib就无法使用。 在Spring AOP中，是通过org.springframework.aop.framework.DefaultAopProxyFactory来判断具体使用哪一种代理方式的，判断依据其实就是有接口则使用JDK动态代理，否则用cglib。 123456789101112131415161718192021222324252627282930313233343536373839404142package org.springframework.aop.framework; import java.io.Serializable;import java.lang.reflect.Proxy; import org.springframework.aop.SpringProxy; @SuppressWarnings(&quot;serial&quot;)public class DefaultAopProxyFactory implements AopProxyFactory, Serializable &#123; @Override public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &#123; if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) &#123; Class&lt;?&gt; targetClass = config.getTargetClass(); if (targetClass == null) &#123; throw new AopConfigException(&quot;TargetSource cannot determine target class: &quot; + &quot;Either an interface or a target is required for proxy creation.&quot;); &#125; //判断如果是接口，或者是被代理的类，则使用JDK动态代理 if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) &#123; return new JdkDynamicAopProxy(config); &#125; //否则用cglib动态代理，（没有实现接口的类） return new ObjenesisCglibAopProxy(config); &#125; else &#123; //默认使用jdk动态代理 return new JdkDynamicAopProxy(config); &#125; &#125; /** * 确定提供的&#123;@link AdvisedSupport&#125;是否仅有 * 指定了&#123;@link org.springframework.aop.SpringProxy&#125;接口 *（或者根本没有指定的代理接口）。 */ private boolean hasNoUserSuppliedProxyInterfaces(AdvisedSupport config) &#123; Class&lt;?&gt;[] ifcs = config.getProxiedInterfaces(); return (ifcs.length == 0 || (ifcs.length == 1 &amp;&amp; SpringProxy.class.isAssignableFrom(ifcs[0]))); &#125; &#125; spring AOP 说到底是一种代理，类似于一个拦截器，所以它可以用在比如统一拦截进行参数校验，权限验证，日志记录等等。 Spring AOP 在使用时，当然也有xml和注解两种，xml就不总结了，感觉注解更方便，需要注意的时使用注解来配置aop，需要依赖AspectJ，AspectJ提供了spring aop的注解支持。启用AspectJ 的方式，通过xml：aop:aspectj-autoproxy/，通过注解：@Configuration中增加@EnableAspectJAutoProxy注解。使用时，通过@Component和@Aspect注解来标注一个切面bean，在该bean中定义切点。四种切点的定义方法见下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Aspectpublic class MyAspect &#123; /** * 前置通知 */ @Before(&quot;execution(* com.zejian.spring.springAop.dao.UserDao.addUser(..))&quot;) public void before()&#123; System.out.println(&quot;前置通知....&quot;); &#125; /** * 后置通知 * returnVal,切点方法执行后的返回值 */ @AfterReturning(value=&quot;execution(* com.zejian.spring.springAop.dao.UserDao.addUser(..))&quot;,returning = &quot;returnVal&quot;) public void AfterReturning(Object returnVal)&#123; System.out.println(&quot;后置通知....&quot;+returnVal); &#125; /** * 环绕通知 * @param joinPoint 可用于执行切点的类 * @return * @throws Throwable */ @Around(&quot;execution(* com.zejian.spring.springAop.dao.UserDao.addUser(..))&quot;) public Object around(ProceedingJoinPoint joinPoint) throws Throwable &#123; System.out.println(&quot;环绕通知前....&quot;); Object obj= (Object) joinPoint.proceed(); System.out.println(&quot;环绕通知后....&quot;); return obj; &#125; /** * 抛出通知 * @param e */ @AfterThrowing(value=&quot;execution(* com.zejian.spring.springAop.dao.UserDao.addUser(..))&quot;,throwing = &quot;e&quot;) public void afterThrowable(Throwable e)&#123; System.out.println(&quot;出现异常:msg=&quot;+e.getMessage()); &#125; /** * 无论什么情况下都会执行的方法 */ @After(value=&quot;execution(* com.zejian.spring.springAop.dao.UserDao.addUser(..))&quot;) public void after()&#123; System.out.println(&quot;最终通知....&quot;); &#125;&#125; execution表达式的三种通配符： .. ：匹配方法定义中的任意数量的参数，此外还匹配类定义中的任意数量包 //任意返回值，任意名称，任意参数的公共方法execution(public * (..))//匹配com.zijian.dao包及其子包中所有类中的所有方法within(com.zijian.dao..) ：匹配给定类的任意子类 //匹配实现了DaoUser接口的所有子类的方法within(com.zijian.dao.DaoUser+) ：匹配任意数量的字符 //匹配com.zijian.service包及其子包中所有类的所有方法within(com.zijian.service..)//匹配以set开头，参数为int类型，任意返回值的方法execution( set*(int)) 参考： https://www.cnblogs.com/junzi2099/p/8274813.html 3 注解和自动注入 @Configuration相当于xml的配置，在@Configration上可以搭配@ComponentScan和@EnableXXX来配置包扫描路径和启用AOP/事务等特性。在@configration中可以用@Bean手动注入一个bean，这种注入方式很灵活，可以传入参数和做一些自定义的初始化操作，在@Bean上还可以配合@Conditional(xxx.class implemens condition)注解实现有条件的注入，可以通过实现conditoin接口，来自定义条件注入的规则。@Configruation通常也和@Import和@ImportResource注解搭配使用，用于引入其他地方配置的bean，其中@Import可以通过三种方式引入，一是指定{xxx.class,xxx.class}直接引入具体的某些类，二是指定实现ImportSelector接口的类，在springboot的注解中可以找到这种使用方式，三是指定实现ImportBeanDefination接口的类。@ImportResource则可以通过指定xml的路径来引入xml中定义的bean。 自动装配有两个注解，@Autowired是spring自己的标签，默认按类型注入，即byType，如果有多个type相同的bean，默认会报错，此时有两种解决方式，一是@Qualifier指定要注入的bean id，另一个是在多个type相同的bean上面用@Primary标注优先加载。另一种情况，没有与之type匹配的bean，默认也会注入失败，此时可以用@Autowired(required=false)来标注。 另一个注解是，@Resource,这是个JSR标准提供的自动装配注解，它比@Autowired更灵活，默认按照Name（id）注入，如果按照name找不到匹配的bean，则自动按照byType方式注入，所以更智能一些。 指定Bean的初始化和销毁方法，有三种方式，一是@Bean(value=xxxx,initMethod=xxx, destroyMethod=xxx)，另一个是在Bean的初始化和销毁方法上用@PostConstructor和PreDestory注解标注，三是可以通过BeanPostProcessor接口拦截所有Bean，针对需要个性化的bean做一些逻辑处理。 4 Spring加载和注入依赖的过程 5 Aware系列接口Spring提供了一系列Aware接口，通过aware接口可以访问到spring提供的一些内部组件，常用的如ApplicationContextAware接口可以让我们获取到ApplicationContext。其他的aware接口后面学习后再补上。","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"JAVA并发拾遗","slug":"JAVA_concurrent","date":"2019-09-13T13:09:33.000Z","updated":"2021-06-21T06:38:19.583Z","comments":true,"path":"2019/09/13/JAVA_concurrent/","link":"","permalink":"http://example.com/2019/09/13/JAVA_concurrent/","excerpt":"","text":"一些容易忘记的知识点，记录一下。 手动创建线程池的方式1234567ThreadFactory namedThreadFactory = new ThreadFactoryBuilder().setNameFormat(&quot;demo-pool-%d&quot;).build();//Common Thread PoolExecutorService pool = new ThreadPoolExecutor(5, 200,0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue&lt;Runnable&gt;(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy()); ThreadPoolExecutor提供了submit和execute方法，其中submit可以提交runnable和callable两种类型的线程，有返回值，并可以抛出异常到外面，被外层感知。 execute只能提交runnable类型的线程，没有返回值，无法抛出异常，有异常只能在内部处理，这是两者的区别。 线程池的类图 Excutorservice提供的三种提交线程的方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * Submits a value-returning task for execution and returns a * Future representing the pending results of the task. The * Future&#x27;s &#123;@code get&#125; method will return the task&#x27;s result upon * successful completion. * * &lt;p&gt; * If you would like to immediately block waiting * for a task, you can use constructions of the form * &#123;@code result = exec.submit(aCallable).get();&#125; * * &lt;p&gt;Note: The &#123;@link Executors&#125; class includes a set of methods * that can convert some other common closure-like objects, * for example, &#123;@link java.security.PrivilegedAction&#125; to * &#123;@link Callable&#125; form so they can be submitted. * * @param task the task to submit * @param &lt;T&gt; the type of the task&#x27;s result * @return a Future representing pending completion of the task * @throws RejectedExecutionException if the task cannot be * scheduled for execution * @throws NullPointerException if the task is null */ &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); /** * Submits a Runnable task for execution and returns a Future * representing that task. The Future&#x27;s &#123;@code get&#125; method will * return the given result upon successful completion. * * @param task the task to submit * @param result the result to return * @param &lt;T&gt; the type of the result * @return a Future representing pending completion of the task * @throws RejectedExecutionException if the task cannot be * scheduled for execution * @throws NullPointerException if the task is null */ &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); /** * Submits a Runnable task for execution and returns a Future * representing that task. The Future&#x27;s &#123;@code get&#125; method will * return &#123;@code null&#125; upon &lt;em&gt;successful&lt;/em&gt; completion. * * @param task the task to submit * @return a Future representing pending completion of the task * @throws RejectedExecutionException if the task cannot be * scheduled for execution * @throws NullPointerException if the task is null */ Future&lt;?&gt; submit(Runnable task); Future接口定义： 12345678910111213 package java.util.concurrent;public interface Future&lt;V&gt; &#123; boolean cancel(boolean var1); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long var1, TimeUnit var3) throws InterruptedException, ExecutionException, TimeoutException;&#125; FutureTask 实现了RunnalbeFuture，RunnalbeFuture的继承了runnable和future两个接口： 1234567891011121314151617/** * A &#123;@link Future&#125; that is &#123;@link Runnable&#125;. Successful execution of * the &#123;@code run&#125; method causes completion of the &#123;@code Future&#125; * and allows access to its results. * @see FutureTask * @see Executor * @since 1.6 * @author Doug Lea * @param &lt;V&gt; The result type returned by this Future&#x27;s &#123;@code get&#125; method */public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; /** * Sets this Future to the result of its computation * unless it has been cancelled. */ void run();&#125; FutureTask的两个构造方法： 12345678910111213public FutureTask(Callable&lt;V&gt; callable) &#123; if (callable == null) &#123; throw new NullPointerException(); &#125; else &#123; this.callable = callable; this.state = 0; &#125; &#125; public FutureTask(Runnable runnable, V result) &#123; this.callable = Executors.callable(runnable, result); this.state = 0; &#125; 可以看到FutureTask可以用来包装一个runnable的线程或者一个callable的线程，执行时，可以直接调用futuretask的run方法或者放入线程池执行，因为它实现了future接口，所以即便直接调用run方法执行，也可以通过其自身的get方法获取结果，以及自身的isDone等方法判断执行状态。FutureTask还可以确保即使调用了多次run方法，它都只会执行一次Runnable或者Callable任务。 关于线程池的复用，线程池能够提高效率的很重要一点是它能够线程复用，避免了线程频繁创建切换的开销，创建一个线程池的同时就初始化了n个线程，后续有任务被提交到线程池后，这些任务会交给其中的某些线程去执行，某个线程的任务执行完毕后，该线程并不会立即销毁，而是转换为空闲状态继续等待下个任务。引用别的文章中的一句话：创建线程变成了从线程池获取空闲的线程，关闭线程变成了向池子中归还线程. 这和直接用Thread的start方法去启动线程的区别在于，直接start会创建一个新的线程，执行完毕后，线程会销毁。线程池的线程复用可能会在使用Threadlocal时带来一些问题，后续研究一下。 关于线程池的拒绝策略，手动初始化ThreadPoolExecutor时需要指定线程池的拒绝策略，ThreadPoolExecutor类以内部类的形式已经提供了四种拒绝策略的默认实现，这些内部类都实现了RejectedExecutionHandler接口，只需要初始化时指定就可以了。 ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程） ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 关于初始化线程池时使用的workQueue（BlockingQueue ），其实这个参数的选择很重要，它制定了线程排队的策略以及队列的长度，常见取值有： ArrayBlockingQueue 基于数组的先进先出队列，此队列创建时必须指定大小 LinkedBlockingQueue 基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为Integer.MAX_VALUE （创建时最好指定长度，不指定容易OOM） SynchronousQueue SynchronousQueue不是一个真正的队列，而是一种线程之间移交的机制。要将一个元素放入SynchronousQueue中，必须有另一个线程正在等待接收这个元素，同步队列没有任何内部容量，甚至连一个队列的容量都没有。只有在使用无界线程池或者有饱和策略时才建议使用该队列。 引用其他文章的解释：SynchronousQueue 内部没有容量，但是由于一个插入操作总是对应一个移除操作，反过来同样需要满足。那么一个元素就不会再SynchronousQueue 里面长时间停留，一旦有了插入线程和移除线程，元素很快就从插入线程移交给移除线程。也就是说这更像是一种信道（管道），资源从一个方向快速传递到另一方 向。显然这是一种快速传递元素的方式，也就是说在这种情况下元素总是以最快的方式从插入着（生产者）传递给移除着（消费者），这在多任务队列中是最快处理任务的方式。在线程池里的一个典型应用是Executors.newCachedThreadPool()就使用了SynchronousQueue，这个线程池根据需要（新任务到来时）创建新的线程，如果有空闲线程则会重复使用，线程空闲了60秒后会被回收。 PriorityBlockingQueue 带有优先级的阻塞队列 上面使用SynchronousQueue的线程池与使用其他blockingqueue的线程池区别在于，SynchronousQueue没有缓冲队列，提交到线程池的任务必须有对应的线程接收处理，它没有最大线程数的限制，所以提交的任务过多时，可能会创建大量线程，导致内存溢出等问题，而其他的blockingqueue，提交到线程池的任务过多达到corePoolSize时可以在缓冲队列等待。 关于线程池的keepAliveTime参数，表示空闲线程的存活实践，因为线程池时存在线程复用的，已经初始化的线程不会被立即销毁，而是转为空闲状态，这个参数表示这些空闲线程的最大存活时间。 任务提交给线程池之后的处理处理过程： 如果当前线程池中的线程数目小于corePoolSize，则每来一个任务，就会创建一个线程去执行这个任务； 如果当前线程池中的线程数目&gt;=corePoolSize，则每来一个任务，会尝试将其添加到任务缓存队列当中，若添加成功，则该任务会等待空闲线程将其取出去执行；若添加失败（一般来说是任务缓存队列已满），则会尝试创建新的线程去执行这个任务； 如果当前线程池中的线程数目达到maximumPoolSize，则会采取任务拒绝策略进行处理； 如果线程池中的线程数量大于 corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止，直至线程池中的线程数目不大于corePoolSize；如果允许为核心池中的线程设置存活时间，那么核心池中的线程空闲时间超过keepAliveTime，线程也会被终止。 参考： https://www.cnblogs.com/dolphin0520/p/3932921.html https://blog.csdn.net/qq_35909080/article/details/87002367","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"JAVA 并发","slug":"JAVA-并发","permalink":"http://example.com/tags/JAVA-%E5%B9%B6%E5%8F%91/"}]},{"title":"设计模式02_工厂模式","slug":"design_pattern02_factory","date":"2019-09-12T13:34:23.000Z","updated":"2021-06-21T06:38:19.113Z","comments":true,"path":"2019/09/12/design_pattern02_factory/","link":"","permalink":"http://example.com/2019/09/12/design_pattern02_factory/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"DesignPattern","slug":"DesignPattern","permalink":"http://example.com/tags/DesignPattern/"}]},{"title":"消息中间件之kafka","slug":"kafka","date":"2019-09-05T13:39:26.000Z","updated":"2021-06-21T06:38:19.621Z","comments":true,"path":"2019/09/05/kafka/","link":"","permalink":"http://example.com/2019/09/05/kafka/","excerpt":"","text":"关于kafka因为在华为技术线的原因，接触的第一个消息中间件就是kafka，华为选择kafka的原因，推测一是kafka多节点集群式部署方便水平扩展，另一个是可靠性和易用性。 kafka是最初LinkedIn公司用Scala语言开发的一个分布式消息系统，后面被捐赠给了Apache基金会。提到消息队列，最常用的应该就是系统解耦和流量削峰提高吞吐量这两大特性，kafka在此基础上，提供了大多数消息系统难以实现的顺序性保障和回溯消费的功能。 kafka中的名词 Producer 生产者 Consumer 消费者 Broker 可以认为是一个独立的kafka服务节点或实例，一个或多个Broker组成了kafka集群 Zookeeper 在kafka集群中负责集群元数据管理和控制节点选举 Topic kafka中的消息以topic为单位归类，发送和接受消息均需要指定特定的topic，注意topic只是一个逻辑概念，它可以分为多个分区，一个分区只属于单个主题。 Partition 分区在存储角度可以看做一个可追加的日志文件，消息被追加到log文件时会指定一个特定的偏移量offset，这个offset是消息在分区中的唯一标识。kafka通过这个offset保证消息在分区内的有序性，所以kafka保证的是分区有序，而不是主题有序。分区有副本机制，一主多从，副本会主动从主节点同步数据，可以通过增加副本数量提高集群的容灾能力。 安装kafkakafka和zookeeper都是基于JVM的服务，所以需要保证先安装了JDK。（kafka基于scala开发，而scala是运行在JVM中的） 先安装zookeeper： 1sudo apt-get install zookeeper 从官网下载kafka安装包， 待续..","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"框架","slug":"框架","permalink":"http://example.com/tags/%E6%A1%86%E6%9E%B6/"}]},{"title":"早七点的外事学院","slug":"morning_at_institute","date":"2019-09-05T00:02:55.000Z","updated":"2021-06-21T06:38:19.647Z","comments":true,"path":"2019/09/05/morning_at_institute/","link":"","permalink":"http://example.com/2019/09/05/morning_at_institute/","excerpt":"","text":"","categories":[{"name":"摄影","slug":"摄影","permalink":"http://example.com/categories/%E6%91%84%E5%BD%B1/"}],"tags":[{"name":"摄影 人文","slug":"摄影-人文","permalink":"http://example.com/tags/%E6%91%84%E5%BD%B1-%E4%BA%BA%E6%96%87/"}]},{"title":"正在消失的鱼化寨","slug":"yuhuazhai","date":"2019-09-04T01:56:55.000Z","updated":"2021-06-21T06:38:19.894Z","comments":true,"path":"2019/09/04/yuhuazhai/","link":"","permalink":"http://example.com/2019/09/04/yuhuazhai/","excerpt":"","text":"","categories":[{"name":"摄影","slug":"摄影","permalink":"http://example.com/categories/%E6%91%84%E5%BD%B1/"}],"tags":[{"name":"摄影 人文","slug":"摄影-人文","permalink":"http://example.com/tags/%E6%91%84%E5%BD%B1-%E4%BA%BA%E6%96%87/"}]},{"title":"八月的温柔","slug":"august","date":"2019-09-03T15:33:55.000Z","updated":"2021-06-21T06:38:18.848Z","comments":true,"path":"2019/09/03/august/","link":"","permalink":"http://example.com/2019/09/03/august/","excerpt":"","text":"一场计划外的严重胃肠感冒扰乱了好几天的节奏，度过了很难受的几天，幸而慢慢好起来。这几天没有精神，原想补补是枝裕和的几部电影，却根本看不下去，今天去操场跑步的时候我才想明白，不是看不进去，是在下意识避免自己受伤，无论是《如父如子》还是《小偷家族》，我喜欢的是他平实朴素的叙事和不加干预的镜头，让人很平静，逃避的是片子里平淡日常背后浓厚的温情，这份温柔是我求而不得的。 前天看到一句诗:“陌上花开，可缓缓归矣”，是南越王写给自己妻子书信中的一句，我特别喜欢。据说当时南越王在杭州办公，出来看见西湖小径边已经是花红柳绿，不由想着寒食节去娘家祭拜的妻子什么时候回来呀，所以情到深处是平常啊，很羡慕这种单纯美好的爱情。想想自己，年二十又六，一颗老心脏更多的是佛系，我只是再也找不回18岁时奋不顾身投入一份感情的状态了，都随缘吧。","categories":[{"name":"Emotion","slug":"Emotion","permalink":"http://example.com/categories/Emotion/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"JAVA技术栈复习笔记14_反射及其应用","slug":"JAVA14_reflect","date":"2019-09-02T13:39:26.000Z","updated":"2021-06-21T06:38:19.565Z","comments":true,"path":"2019/09/02/JAVA14_reflect/","link":"","permalink":"http://example.com/2019/09/02/JAVA14_reflect/","excerpt":"","text":"基础用法自定义注解与反射动态代理Spring中的应用类加载器和权限验证","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://example.com/tags/JAVA/"}]},{"title":"在西藏","slug":"tibet","date":"2019-09-01T13:56:55.000Z","updated":"2021-06-21T06:38:19.861Z","comments":true,"path":"2019/09/01/tibet/","link":"","permalink":"http://example.com/2019/09/01/tibet/","excerpt":"8月中旬，临时起意订了去拉萨的机票。一个人出行，并没有什么顾虑，信马由缰。","text":"8月中旬，临时起意订了去拉萨的机票。一个人出行，并没有什么顾虑，信马由缰。","categories":[{"name":"Travel","slug":"Travel","permalink":"http://example.com/categories/Travel/"}],"tags":[{"name":"旅行 西藏 摄影","slug":"旅行-西藏-摄影","permalink":"http://example.com/tags/%E6%97%85%E8%A1%8C-%E8%A5%BF%E8%97%8F-%E6%91%84%E5%BD%B1/"}]},{"title":"Redis02_数据结构","slug":"Redis02_data_structure","date":"2019-08-30T13:15:38.000Z","updated":"2021-06-21T06:38:19.755Z","comments":true,"path":"2019/08/30/Redis02_data_structure/","link":"","permalink":"http://example.com/2019/08/30/Redis02_data_structure/","excerpt":"String即key(String) &lt;-&gt; value(String)的数据结构 支持普通字符串、整数、浮点数，对于后面两者可以使用incr和decr等命令进行自增和自减操作 最大长度：512M 存储策略：类似于Java的Arraylist，根据要存入的字符串大小给定一个初始容量（一般大于要存储的字符串），当字符串长度小于1M时，扩容时double现有的空间，当超过1M，按照每次增加1M 来扩容 缓存 普通字符串则简单存取，复杂对象可以序列化为Json字符串存储， 读取时相应进行反序列化操作 常用命令： GET SET DEL INCR incr [key-name] DECR INCRBY incr [key-name] [amout] DECRBY INCRBYFLOAT 注意： 对于后面的自增或者自减操作，如果key值不存在，或者key对应的value为null，则redis默认将该键的value当做0处理，而不会报错。 如果某个key对应的value无法被转换为数字，则incr或者decr命令将报错。 对于字符串，redis提供了一系列对子串处理的命令，如append getbit setbit等，之前在掘金上看到有大佬利用这些命令做一些黑科技操作，能方便的解决某些场景的问题，我这暂时还没研究。","text":"String即key(String) &lt;-&gt; value(String)的数据结构 支持普通字符串、整数、浮点数，对于后面两者可以使用incr和decr等命令进行自增和自减操作 最大长度：512M 存储策略：类似于Java的Arraylist，根据要存入的字符串大小给定一个初始容量（一般大于要存储的字符串），当字符串长度小于1M时，扩容时double现有的空间，当超过1M，按照每次增加1M 来扩容 缓存 普通字符串则简单存取，复杂对象可以序列化为Json字符串存储， 读取时相应进行反序列化操作 常用命令： GET SET DEL INCR incr [key-name] DECR INCRBY incr [key-name] [amout] DECRBY INCRBYFLOAT 注意： 对于后面的自增或者自减操作，如果key值不存在，或者key对应的value为null，则redis默认将该键的value当做0处理，而不会报错。 如果某个key对应的value无法被转换为数字，则incr或者decr命令将报错。 对于字符串，redis提供了一系列对子串处理的命令，如append getbit setbit等，之前在掘金上看到有大佬利用这些命令做一些黑科技操作，能方便的解决某些场景的问题，我这暂时还没研究。 ListRedis中的List是一个链表结构，意味着插入和删除有较好的性能。 常用命令： LPUSH RPUSH 这两个push命令都是支持一次push多个元素进去的，用空格隔开就好 LPOP RPOP LRANGE LINDEX LTRIM 一个截取命令 ltrim key-name start end 截取起止位置的子列表 start和end的元素也会保留 List还提供了一系列阻塞命令，可以应用这些阻塞命令实现阻塞队列。 BLPOP、BRPOP 如 blpop key-name [key-name …] timeout 从第一个非空列表中弹出位于最左边的元素，如果没有元素，则阻塞，直到有可弹出元素或者超时 RPOPPUSH 如 rpoppush source-key dest-key 从source-key最右边弹出一个元素，然后push到dest-key的最左边，并向用户返回这个元素。 BRPOPPUSH 上面命令的阻塞版本，也支持在最后设置timeout Hash常用命令： HGET HSET HDEL HGETALL HMGET HMSET HLEN HKEYS HEXISTS HINCRBY hincrby key-name key amount Set常用命令： SADD SREM SISMEMBER SMEMBERS SCARD 返回包含的元素数量 集合还支持多个集合间的运算命令： SDIFF sdiff key-name1 key-name2 [key-name …] SDIFFSTORE sdiff dest-key key-name1 key-name2 [key-name …] SINTER SINTERSTORE SUNION SUNIONSTORE 分别对应差集，交集，合集。带store的命令是将结果保存到dest-key。 Zset注意ZSet存储的也是键值对，而非单个字符串，key为键值，value为score，这个score也是Zset排序的依据，为一个浮点数。 所以从存储角度上，ZSet更类似于Hash而不是Set。 常用命令： ZADD 添加元素时，需要带上score，如 zadd myzsetkey 999 member1 ZREM ZRANGE 按照元素的索引位置范围来获取元素，可以在最后加上withscores来返回元素的score值 ZRANGEBYSCORE 按照元素的score范围来获取元素，可以在最后加上withscores来返回元素的score值 ZCARD ZINCRBY zincrby key-name member amount 分值加上指定的数量 Redis提供了通用的sort命令，可以对上面五种数据结构进行排序，类似sql的order by sort key-name [limit offset count] [asc | desc] [store dest-key] 参考： 《Redis in action》 中国工信出版社。","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}]},{"title":"Redis01_概览","slug":"Redis01_about","date":"2019-08-30T09:40:38.000Z","updated":"2021-06-21T06:38:19.744Z","comments":true,"path":"2019/08/30/Redis01_about/","link":"","permalink":"http://example.com/2019/08/30/Redis01_about/","excerpt":"","text":"Redis的特点 提供了很丰富的数据结构和命令 可以方便灵活的的应用到实际场景中 可持久化（快照或AOF） 支持主从复制 建立集群 以扩展性能 与另一个no sql 数据库memcached相比， memcached只支持普通字符串，且不支持持久化。 Redis 发布和订阅Redis 提供了发布和订阅的命令，因此可以在可靠性要求不高的场景作为消息队列使用。 SUBSCRIBE subscribe channel [channel] 订阅一个或多个channel UNSUBSCRIBE PUBLISH publish channel message 向某个频道发消息 PSUBSCRIBE psubscribe pattern [pattern] 订阅与给定模式匹配的所有channel PUNSUBSCRIBE 缺点： 如果消息消费者的处理能力有限，有可能会有大量消息堆积在Redis输出缓冲区，导致Redis性能下降，甚至崩溃。 新版Redis不会出现该问题， 它会自动断开不符合client-output-buffer-limit pubsub选项要求的客户端。 可靠性差，如果网络错误等原因导致客户端失联，消息会丢失。 Redis 事务使用multi和exec命令来实现事务，发送multi给redis后，redis会将multi后发送的所有命令放到缓冲队列，并不立即执行，而是等收到exec后，将这一系列命令统一执行。multi和exec能保证一个客户端发来的命令可以原子执行，但是并不能保证多个客户端对同一个数据进行操作时的数据一致性，这时候就需要搭配watch和unwatch机制来控制。多个客户端操作同一个key，可以先用watch命令对该key添加一个监视，然后进行multi和exec，在exec之前，如果有其他客户端修改该key，它会收到一个错误，并可以根据该错误自行决定重试或放弃。Redis这种事务模式相比于传统关系数据库对临界资源加锁的方式，是一种乐观锁，即，优先假设不会冲突，通过二次检查机制来确定是否有冲突，有则自行决定重试或放弃，因为是非阻塞的，理论上效率更高。而对临界资源加锁，则优先假设会发生冲突，一个客户端操作时，其他客户端只能阻塞，效率差。 unwatch可以在watch执行后，multi执行前，对连接重置，取消监视。dicard可以在multi执行后，exec执行前，对连接重置，清空multi后已入队的所有命令。 Redis 持久化 快照 SAVE 指令：服务器停止响应客户端指令，并开始创建快照，直到快照创建完成，很少使用 ，因为阻塞。 BGSAVE 指令： 服务器会创建一个子进程，负责创建快照，主进程继续响应客户端指令。 注： 配置选项： save 60 10000 表示如果60s内有10000次写入，就会自动触发BGSAVE指令，如果设置了多个save配置，任意一个设置的条件被满足，就会触发BGSAVE。 缺点： 数据丢失。 快照相当于定时备份，有可能会丢失从上次备份到现在的一部分数据。 停顿。 在数据量很大时，受限于硬件和虚拟化技术，执行bgsave系统创建子进程可能会有长时间停顿，导致Redis性能减低甚至短时间无法使用。（XEN虚拟机上的Redis服务器在20G数据量运行BGSAVE停顿4~6s） AOF 即将每一次写入指令都持久化到AOF文件中，可以选择将 appendfsync设置为 always、everysec、no 来同步。always 表示所有写入指令都会append到aof文件中，这对存储设备要求很高，在固态硬盘下，可能引发写入放大，使寿命减少，所以一般采用everysec，即一秒钟写入一次，即便丢失，也只丢失一秒内的数据。 缺点： AOF文件的体积会变得非常大，甚至占满可用空间，Redis在重启后需要重新执行AOF还原数据，文件很大的情况下，还原可能会很长。 可以通过BGREWRITEAOF指令重写AOF文件，该指令创建子进程删除AOF中的冗余指令。 参考： 《Redis in action》 中国工信出版社。","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}]},{"title":"7月随想","slug":"july_emotion","date":"2019-08-05T14:33:55.000Z","updated":"2021-06-21T06:38:19.591Z","comments":true,"path":"2019/08/05/july_emotion/","link":"","permalink":"http://example.com/2019/08/05/july_emotion/","excerpt":"","text":"晚上，总算想起来，把评论系统加上了，这个小破站，圆满了。 回来路上，偶见知乎一个关于读书的回答： 不读书不见得是什么坏事，因为有时候读书越多，人世就越冷。 已经不能更赞同了吧，人一旦开始学习，开始思考，就开始了忧患怀疑的一生，我的诸多烦扰，何不是思虑过重？一切都看通透，一切便也无聊，不如做一个封建王朝的愚民，苦些累些，却能轻易满足，获得淳朴简单的幸福。所以，读书这件事，有点像修炼武功，如果内心不够强大，看多了各种功法，很容易迷失剑心。只希望，自己能人格坚固，向阳而生，在这个无聊冷漠的世界里，依然看到光。 到今年七月，来西安正好两年，习惯了大口吃面，习惯了日常加班，也遇到很照顾自己的领导、朋友，没大大的完美，但有小小的幸运。到今天，蓄谋已久的离职也就剩这么十几天，时常觉得自己很矛盾，渴望稳定坚固的人际关系和生活，但又无法忍受日复一日的重复，离家甚远，没有束缚，却也鲜有支持，自己折腾，自己负责，就是这几年的主旋律。不管怎样，选择折腾，就加油吧，行动胜于无所谓的思考。 七月初，工作不忙，从一本《北京 1643》开始，读到《万历十五年》，自始至终，都很想搞清楚明朝灭亡的根因，许是因为它是中国最后一个由汉人掌权的大统一王朝，大厦颓然倾覆才让我觉得可惜。1644，李自成破城的第二天，从内阁首辅家中搜出3百万两黄金，如果已经吊死在景山的崇祯知道，表情一定会很精彩，一个制度僵化，内部被士绅官员层层吸血的国家，碰到一个优柔挂断，刚愎自用的君主，终究走到尽头。读历史，很无奈的一点是，你开了上帝视角，看着前人一步步犯错，拼了命挣扎，或愚忠坚守，或苟且偷生，但什么都改变不了。 改变的了的只能是自己。 没有期待，但有坚持。","categories":[{"name":"Emotion","slug":"Emotion","permalink":"http://example.com/categories/Emotion/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"风","slug":"wind","date":"2019-08-05T13:01:55.000Z","updated":"2021-06-21T06:38:19.877Z","comments":true,"path":"2019/08/05/wind/","link":"","permalink":"http://example.com/2019/08/05/wind/","excerpt":"七月风吹皱行人影寂静心绪追赶着古都的天","text":"七月风吹皱行人影寂静心绪追赶着古都的天 又初七羞赧纠缠的秘密像雪重复在雪中穿过彷徨沙海说与洄游的鱼 若初见醉在眸间星河的倒影清梦满船 梦呓里风吹落银河吹不散你","categories":[{"name":"Poetry","slug":"Poetry","permalink":"http://example.com/categories/Poetry/"}],"tags":[{"name":"诗","slug":"诗","permalink":"http://example.com/tags/%E8%AF%97/"}]},{"title":"2017-05 旅拍","slug":"201705travel","date":"2019-07-30T13:56:55.000Z","updated":"2021-06-21T06:38:18.660Z","comments":true,"path":"2019/07/30/201705travel/","link":"","permalink":"http://example.com/2019/07/30/201705travel/","excerpt":"","text":"","categories":[{"name":"Travel","slug":"Travel","permalink":"http://example.com/categories/Travel/"}],"tags":[{"name":"旅行","slug":"旅行","permalink":"http://example.com/tags/%E6%97%85%E8%A1%8C/"}]},{"title":"线程池(一)","slug":"threadpool01","date":"2019-07-24T12:30:38.000Z","updated":"2021-06-21T06:38:19.850Z","comments":true,"path":"2019/07/24/threadpool01/","link":"","permalink":"http://example.com/2019/07/24/threadpool01/","excerpt":"在正式项目里，我们会把线程放到线程池里执行，而通常框架会封装好一个现成的thread pool供业务使用，但如果遇到需要自己创建的情况，要怎样初始化一个线程池呢？ JDK中有提供Executors工厂类用于创建线程池，但是不推荐，至于原因，在阿里的Java开发手册中已经说的很清楚了： 线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。说明：Executors返回的线程池对象的弊端如下：1）FixedThreadPool和SingleThreadPool: 允许的请求队列长度为Integer.MAX_VALUE，可能会堆积大量的请求，从而导致OOM。2）CachedThreadPool: 允许的创建线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致OOM。","text":"在正式项目里，我们会把线程放到线程池里执行，而通常框架会封装好一个现成的thread pool供业务使用，但如果遇到需要自己创建的情况，要怎样初始化一个线程池呢？ JDK中有提供Executors工厂类用于创建线程池，但是不推荐，至于原因，在阿里的Java开发手册中已经说的很清楚了： 线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。说明：Executors返回的线程池对象的弊端如下：1）FixedThreadPool和SingleThreadPool: 允许的请求队列长度为Integer.MAX_VALUE，可能会堆积大量的请求，从而导致OOM。2）CachedThreadPool: 允许的创建线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致OOM。 在手册中，给出了几个示例写法： Positive example 1： 123//org.apache.commons.lang3.concurrent.BasicThreadFactoryScheduledExecutorService executorService = new ScheduledThreadPoolExecutor(1, new BasicThreadFactory.Builder().namingPattern(&quot;example-schedule-pool-%d&quot;).daemon(true).build()); Positive example 2： 12345678910ThreadFactory namedThreadFactory = new ThreadFactoryBuilder() .setNameFormat(&quot;demo-pool-%d&quot;).build();//Common Thread PoolExecutorService pool = new ThreadPoolExecutor(5, 200, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy());pool.execute(()-&gt; System.out.println(Thread.currentThread().getName()));pool.shutdown();//gracefully shutdown Positive example 3： 12345678910111213&lt;bean id=&quot;userThreadPool&quot; class=&quot;org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor&quot;&gt; &lt;property name=&quot;corePoolSize&quot; value=&quot;10&quot; /&gt; &lt;property name=&quot;maxPoolSize&quot; value=&quot;100&quot; /&gt; &lt;property name=&quot;queueCapacity&quot; value=&quot;2000&quot; /&gt;&lt;property name=&quot;threadFactory&quot; value= threadFactory /&gt; &lt;property name=&quot;rejectedExecutionHandler&quot;&gt; &lt;ref local=&quot;rejectedExecutionHandler&quot; /&gt; &lt;/property&gt;&lt;/bean&gt;//in codeuserThreadPool.execute(thread); 上面的示例2其实只是简单改造了下JDK自带的Executors.newSingleThreadExecutor()， 给阻塞队列指定了长度：LinkedBlockingQueue&lt;Runnable&gt;(1024),来避免大量的活动线程被加入到线程池导致内存资源耗尽的隐患。","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"Spring 单例和多例","slug":"Spring_singleton","date":"2019-07-24T12:15:38.000Z","updated":"2021-06-21T06:38:19.841Z","comments":true,"path":"2019/07/24/Spring_singleton/","link":"","permalink":"http://example.com/2019/07/24/Spring_singleton/","excerpt":"Spring 容器初始化bean时默认是单例的，即对同一个Bean，容器只会创建一个对应的实例，我们可以通过声明scope属性改变默认的创建模式。需要注意的是，多线程场景一定要考虑到共享变量的数据一致性问题。目前流行的Spring mvc基于Spring，默认也是单例的，作为对比，struts2中的action默认是多例的，每一个请求都会new一个新的action，不过如果struts2和spring整合到一起，使用spring来管理action，那也就变成默认单例的了。 至于到底要用单例还是多例还是要看具体的使用场景。","text":"Spring 容器初始化bean时默认是单例的，即对同一个Bean，容器只会创建一个对应的实例，我们可以通过声明scope属性改变默认的创建模式。需要注意的是，多线程场景一定要考虑到共享变量的数据一致性问题。目前流行的Spring mvc基于Spring，默认也是单例的，作为对比，struts2中的action默认是多例的，每一个请求都会new一个新的action，不过如果struts2和spring整合到一起，使用spring来管理action，那也就变成默认单例的了。 至于到底要用单例还是多例还是要看具体的使用场景。 在xml中配置scope: 1&lt;bean id=&quot;testAction&quot; class=&quot;com.test.TestAction&quot; scope=&quot;prototype&quot;&gt; 使用注解： 12345@RestController@Scope(&quot;prototype&quot;)public class TestAction extends BaseController&#123; ...&#125; scope的取值： singleton： 单一实例 prototype： 多例 request: 针对Web项目，对每一个http请求创建一个新的实例，该实例的生命周期与请求的生命周期一致，请求结束，销毁对象 session:针对Web项目，对每一个session创建一个新的实例，该实例的生命周期与会话保持的时间一致，比request scope的bean会存活更长的时间。 globalsession:只有应用在基于porlet的web应用程序中才有意义，它映射到porlet的global范围的session，如果普通的servlet的web 应用中使用了这个scope，容器会把它作为普通的session的scope对待","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"0724~0831完全自律挑战","slug":"0626to0831selfdiscipline","date":"2019-06-25T14:44:38.000Z","updated":"2021-06-21T06:38:18.617Z","comments":true,"path":"2019/06/25/0626to0831selfdiscipline/","link":"","permalink":"http://example.com/2019/06/25/0626to0831selfdiscipline/","excerpt":"","text":"RT， 不忘初心， 方得始终","categories":[{"name":"Emotion","slug":"Emotion","permalink":"http://example.com/categories/Emotion/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"SpringBoot笔记","slug":"SpringBoot_notes","date":"2019-06-22T01:44:38.000Z","updated":"2021-06-21T06:38:19.831Z","comments":true,"path":"2019/06/22/SpringBoot_notes/","link":"","permalink":"http://example.com/2019/06/22/SpringBoot_notes/","excerpt":"1 创建SpringBoot Demo工程选择了IDEA旗舰版， new project，选择SpringBoot Initailizer 向导即可，目前只有旗舰版才有SpringBoot的插件支持。 创建完成后，发现工程里有个.mvn目录以及mvnw和mvnw.cmd脚本， 查资料发现，mvnw是一个maven wrapper， 如果本地系统没有安装maven或者本地的maven与当前springboot要求的maven版本不匹配时，就可以使用前面说道的mvnw脚本来替代系统maven执行maven指令，比如./mvnw clean。","text":"1 创建SpringBoot Demo工程选择了IDEA旗舰版， new project，选择SpringBoot Initailizer 向导即可，目前只有旗舰版才有SpringBoot的插件支持。 创建完成后，发现工程里有个.mvn目录以及mvnw和mvnw.cmd脚本， 查资料发现，mvnw是一个maven wrapper， 如果本地系统没有安装maven或者本地的maven与当前springboot要求的maven版本不匹配时，就可以使用前面说道的mvnw脚本来替代系统maven执行maven指令，比如./mvnw clean。","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"Deepin的一些使用感受","slug":"Deepin_about","date":"2019-05-29T13:38:38.000Z","updated":"2021-06-21T06:38:18.980Z","comments":true,"path":"2019/05/29/Deepin_about/","link":"","permalink":"http://example.com/2019/05/29/Deepin_about/","excerpt":"陆续用过很多linux发行版，最早的ubuntu、fedora，到后来的arch linux、suse，这些系统除了arch之外，提供的默认界面都差强人意，安装完之后总是要倒腾各种主题，对gtk、gnome做各种美化，除此之外，还要倒腾office、wine、换源等等，以便把一些常用软件跑起来，虽然最终效果都还不错，但是为什么不能一步到位呢？ 直到最近换到了deepin，感觉打开了新世界的大门，系统本身提供的UI风格统一，简洁高效，几乎不需要做任何优化就可以拿来即用，而且软件生态感觉是用过的发行版中最丰富的，这也跟deepin的商业性质有关吧。 把sublime，idea，pycharm 配好，就可以开始干活了，嗯，真香。","text":"陆续用过很多linux发行版，最早的ubuntu、fedora，到后来的arch linux、suse，这些系统除了arch之外，提供的默认界面都差强人意，安装完之后总是要倒腾各种主题，对gtk、gnome做各种美化，除此之外，还要倒腾office、wine、换源等等，以便把一些常用软件跑起来，虽然最终效果都还不错，但是为什么不能一步到位呢？ 直到最近换到了deepin，感觉打开了新世界的大门，系统本身提供的UI风格统一，简洁高效，几乎不需要做任何优化就可以拿来即用，而且软件生态感觉是用过的发行版中最丰富的，这也跟deepin的商业性质有关吧。 把sublime，idea，pycharm 配好，就可以开始干活了，嗯，真香。 Deepin的一些优化1 标题栏太宽 进入主题目录 cd /usr/share/aurorae/themes , 系统默认有两个主题 deepin和deepin-dark， 进入到对应目录下，编辑 sudo deepin-editor deepinrc 文件， 将下面三个选项的值改小一点即可： 12345TitleHeight=40ButtonWidth=40ButtonHeight=40 chrome浏览器的标题栏可以隐藏： 在chrome设置中把使用系统标题栏和边框的选项去掉。 2 全局搜索工具 在windows下用惯了wox+everything，以及mac上的afred，就很难离开搜索工具，linux上推荐下面两个： https://ulauncher.io/ https://cerebroapp.com/ 官网上都有现成的安装包，我目前使用的是ulauncher。","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"Deepin","slug":"Deepin","permalink":"http://example.com/tags/Deepin/"}]},{"title":"阿里Java开发手册和静态检查插件","slug":"aliJavadev_handbook","date":"2019-05-29T12:43:38.000Z","updated":"2021-06-21T06:38:18.803Z","comments":true,"path":"2019/05/29/aliJavadev_handbook/","link":"","permalink":"http://example.com/2019/05/29/aliJavadev_handbook/","excerpt":"1 阿里巴巴JAVA开发手册阿里云官网下载地址： 阿里巴巴JAVA开发手册 2 在IDEA中使用静态检查插件直接在IDEA在线插件market中搜索alibaba， 安装alibaba java coding guideline即可：","text":"1 阿里巴巴JAVA开发手册阿里云官网下载地址： 阿里巴巴JAVA开发手册 2 在IDEA中使用静态检查插件直接在IDEA在线插件market中搜索alibaba， 安装alibaba java coding guideline即可： 3 在IDEA中配置阿里的代码风格模板因为 阿里提供的模板是 eclipse的 formatter文件， 要在IDEA中使用的话，需要安装 EclipseCodeFormatter插件。 模板和使用参见：https://github.com/alibaba/p3c","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"关于徒步","slug":"hike","date":"2019-05-27T13:47:26.000Z","updated":"2021-06-21T06:38:19.415Z","comments":true,"path":"2019/05/27/hike/","link":"","permalink":"http://example.com/2019/05/27/hike/","excerpt":"计划来年的新疆旅行时，曾给自己提出一个要求，即日常锻炼身体，并针对性进行几次徒步训练。 不如从这个月开始，每月固定来一次不少于15KM的徒步。 25号下午5:00， 顶着33度的热浪，开始了古城墙环城徒步，话说来过永宁门好几次，却从没完整的走完过，那时大抵是因为没有执念吧，做什么都很佛系，这样看的话，人还是要有点追求，时不时逼自己一把的。 可能是因为鞋子的原因，走到8km时，脚掌前面就开始起泡，后半段走的异常艰难，想想当时爬黄山，走了不止30KM，身体可没有这么不堪，难道这两年给呆废掉了？","text":"计划来年的新疆旅行时，曾给自己提出一个要求，即日常锻炼身体，并针对性进行几次徒步训练。 不如从这个月开始，每月固定来一次不少于15KM的徒步。 25号下午5:00， 顶着33度的热浪，开始了古城墙环城徒步，话说来过永宁门好几次，却从没完整的走完过，那时大抵是因为没有执念吧，做什么都很佛系，这样看的话，人还是要有点追求，时不时逼自己一把的。 可能是因为鞋子的原因，走到8km时，脚掌前面就开始起泡，后半段走的异常艰难，想想当时爬黄山，走了不止30KM，身体可没有这么不堪，难道这两年给呆废掉了？ 这次徒步的几个教训： 宽松的运动鞋和不磨脚的袜子 提前安排好休息的时间，每6km休息10分钟，超过10KM的路程，不要从头走到尾。 不清楚周围环境的话，一定要提前带好足够的水 运动后准备好盐水和蛋白质，补充流失的电解质和能量 一定要保证充足的休息 绝对不要因为身体的疲劳放松对作息的控制 下个月，骊山或华山走起。","categories":[{"name":"Emotion","slug":"Emotion","permalink":"http://example.com/categories/Emotion/"}],"tags":[{"name":"徒步","slug":"徒步","permalink":"http://example.com/tags/%E5%BE%92%E6%AD%A5/"}]},{"title":"我的断舍离实践","slug":"duansheli","date":"2019-05-23T14:36:26.000Z","updated":"2021-06-21T06:38:19.360Z","comments":true,"path":"2019/05/23/duansheli/","link":"","permalink":"http://example.com/2019/05/23/duansheli/","excerpt":"断： 断绝不必要的东西 舍： 舍弃多余的废物 离： 脱离对物品的执着 断舍离的核心在于以人为本，而不是被物品和欲望所支配。山下英子说幸福取决于我们和里世界相处的能力，即与本我对话的能力，当是否拥有一样物品，或者是否要做一件事情，都简单的变成问自己：我是否真的需要这样物品？我是否主动想去做这件事情？答案会变得明朗起来，很多烦恼也就不复存在了。","text":"断： 断绝不必要的东西 舍： 舍弃多余的废物 离： 脱离对物品的执着 断舍离的核心在于以人为本，而不是被物品和欲望所支配。山下英子说幸福取决于我们和里世界相处的能力，即与本我对话的能力，当是否拥有一样物品，或者是否要做一件事情，都简单的变成问自己：我是否真的需要这样物品？我是否主动想去做这件事情？答案会变得明朗起来，很多烦恼也就不复存在了。 五一期间，收拾屋子，我扔掉了约4个收纳箱的杂物，清理了淘宝的购物车，卸载了12个手机上不必要的软件，对于是否买性能更好的电脑有了明确的答案； 在滴答清单上，我创建了一个重复任务，即每天吃饭走路睡前不碰手机，希望借此养成习惯。 丢弃物品的带来的空白最好由精神上的丰富来弥补，参加线下活动，读书，旅行，遇见生活中的小确幸。 谨慎的拥有每一件物品，认真的审视每一次选择，当断则断，应舍则舍，过好每一天，自勉。","categories":[{"name":"Emotion","slug":"Emotion","permalink":"http://example.com/categories/Emotion/"}],"tags":[{"name":"断舍离","slug":"断舍离","permalink":"http://example.com/tags/%E6%96%AD%E8%88%8D%E7%A6%BB/"}]},{"title":"JAVA技术栈复习笔记11_新特性","slug":"JAVA11_newfeature","date":"2019-05-23T13:11:38.000Z","updated":"2021-06-21T06:38:19.539Z","comments":true,"path":"2019/05/23/JAVA11_newfeature/","link":"","permalink":"http://example.com/2019/05/23/JAVA11_newfeature/","excerpt":"1 JDK7: try-with-resource 最近在做代码检视的时候，发现从2.6版本开始，apache的common-io包里的IOUtils.closeQuietly方法变成了@deprecated的方法，也就是不推荐使用的方法，在网上查资料发现可能跟JDK7开始提供的try-with-resource语法糖有关系，try-with-resource是官方提供的一种更优雅的关闭流的方式，从简洁程度上还要超过IOUtils.closeQuietly。","text":"1 JDK7: try-with-resource 最近在做代码检视的时候，发现从2.6版本开始，apache的common-io包里的IOUtils.closeQuietly方法变成了@deprecated的方法，也就是不推荐使用的方法，在网上查资料发现可能跟JDK7开始提供的try-with-resource语法糖有关系，try-with-resource是官方提供的一种更优雅的关闭流的方式，从简洁程度上还要超过IOUtils.closeQuietly。 解释一个知识点，我觉得基本可以从四个方面入手，即： 是什么？怎么用？原理？ 注意点？后续的笔记我都按照这个套路来总结。 1.1 是什么？try-with-resource 是JDK7 提供的一个语法糖，用于更简洁的关闭流。 以往，关闭流一般是在try-catch-finally的finally语句块中直接调用流自身的close方法，close方法还可能抛出异常，写起来很麻烦。 语言都是在进步和借鉴的，比如python提供的with关键字能够自动的关闭流，这样可以让开发者不必关注外部资源句柄的回收，相应的JDK7提供的try-with-resource也是这样的出发点。 1.2 怎么用？语法格式： 12345try (FileInputStream inputStream = new FileInputStream(new File(&quot;test&quot;))) &#123; System.out.println(inputStream.read());&#125; catch (IOException e) &#123; throw new RuntimeException(e.getMessage(), e);&#125; 其实就是把外部资源句柄的定义写在try后面的()里， 无论try语句块内部是否发生异常，jdk会确保流的close方法一定会被调用。 需要注意的： 写在try()中的外部资源句柄必须实现了AutoCloseable接口，也就是说，在try()里的语句不能是任意一个赋值语句，new出来或者其他方式初始化的对象必须实现AutoCloseable接口，JDK的IO API定义的流对象都已经实现了该接口，所以可以直接用。 try()中可以定义多个赋值语句，多个语句之间用分号分隔，要注意的是，最后一个语句后面不要带分号。 1.3 原理？前面也说了，这是一个语法糖，在编译期间，try-with-resource语句会被还原成传统的try-with-finally模式，即在try语句块外面套一层try-with-finally， 流的关闭还是在finally中定义。关于这一点，可以写一个try-with-resource的实例，编译后，再反编译出来看一下: 1234567891011121314151617181920212223242526272829303132public class Test &#123; public Test() &#123; &#125; public static void main(String[] args) &#123; try &#123; FileInputStream inputStream = new FileInputStream(new File(&quot;test&quot;)); Throwable var2 = null; try &#123; System.out.println(inputStream.read()); &#125; catch (Throwable var12) &#123; var2 = var12; throw var12; &#125; finally &#123; if (var2 != null) &#123; try &#123; inputStream.close(); &#125; catch (Throwable var11) &#123; var2.addSuppressed(var11); &#125; &#125; else &#123; inputStream.close(); &#125; &#125; &#125; catch (IOException var14) &#123; var14.printStackTrace(); &#125; &#125;&#125; 1.4 注意点？ 异常的抑制: 因为流的关闭方法也会抛出异常，该异常怎么处理？在try-with-resource中，如果关闭流时发生了异常，该异常会被抑制，也就是说不会显式的被外面的catch捕获到，之所以说是显式，是因为java在处理时，该异常通过addSuppressed方法添加到suppressed类型的异常里，在外面的catch里，可以通过getSuppressed方法把该异常取出来，具体见上面反编译后的代码。 变量属性: 在try()中定义的外部资源句柄会被隐式定义为final类型，即在try{}中无法改变其指向，考虑到它的实现原理，这也很容易理解。","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://example.com/tags/JAVA/"}]},{"title":"Docker简介","slug":"Docker_about","date":"2019-05-23T13:09:33.000Z","updated":"2021-06-21T06:38:19.333Z","comments":true,"path":"2019/05/23/Docker_about/","link":"","permalink":"http://example.com/2019/05/23/Docker_about/","excerpt":"Docker是什么？ Docker 是一个开源应用容器引擎，Docker容器存放应用及应用的运行环境，基于沙箱机制，它有两个特点： 一是独立，容器与容器之间互相独立运行； 二是可移植，可以方便的从一个机器移植到另一个机器。当前Docker有两个版本，CE版本为社区版，EE为商业版。 Docker的组成部分 镜像 类似使用虚拟机镜像创建ECS， Docker镜像可以用于创建一个Docker容器，镜像相当与容器的一个模板，可以使用一个模板实例化多个相同的Docker容器。 容器 即独立运行应用和应用运行环境的一个容器 客户端 通过命令行或者其他途径与Docker守护进程通信，即client发送命令给Docer守护进程处理，完毕后接收守护进程的响应 主机 一个用于运行Docer守护进程的计算节点 仓库 镜像仓库，类比一下Maven仓库用于管理jar，同时，Docker镜像仓库的行为也和Maven仓库类似，都是优先从本地仓库查找镜像，如果不存在，则默认从中央仓库Docker Hub想在公共镜像 Docker Machine 一个简化Docker安装的命令行工具，通过一个简单的命令行即可在相应的平台上安装Docker，比如VirtualBox、Microsoft Azure","text":"Docker是什么？ Docker 是一个开源应用容器引擎，Docker容器存放应用及应用的运行环境，基于沙箱机制，它有两个特点： 一是独立，容器与容器之间互相独立运行； 二是可移植，可以方便的从一个机器移植到另一个机器。当前Docker有两个版本，CE版本为社区版，EE为商业版。 Docker的组成部分 镜像 类似使用虚拟机镜像创建ECS， Docker镜像可以用于创建一个Docker容器，镜像相当与容器的一个模板，可以使用一个模板实例化多个相同的Docker容器。 容器 即独立运行应用和应用运行环境的一个容器 客户端 通过命令行或者其他途径与Docker守护进程通信，即client发送命令给Docer守护进程处理，完毕后接收守护进程的响应 主机 一个用于运行Docer守护进程的计算节点 仓库 镜像仓库，类比一下Maven仓库用于管理jar，同时，Docker镜像仓库的行为也和Maven仓库类似，都是优先从本地仓库查找镜像，如果不存在，则默认从中央仓库Docker Hub想在公共镜像 Docker Machine 一个简化Docker安装的命令行工具，通过一个简单的命令行即可在相应的平台上安装Docker，比如VirtualBox、Microsoft Azure 通常情况下，Docker client和Docker server会同时部署在同一台机器上，一个host上运行对应的两个进程。 Docker 常用命令 docker version 查看版本 docker ps 查看当前正在运行的容器；-a 选项可以查看所有容器，包括未运行的 docker images 查看本地镜像 docker search ubuntu 从镜像库查找镜像 docker pull ubuntu:6.04 从镜像repo拉取指定镜像 docker run -it ubuntu:16.04 -p 5000:5000/bin/bash 启动一个ubuntu容器。-t选项表示在容器内分配一个终端，即terminal；-i表示允许对容器以标准输入stdin进行交互，通常我们会用-d选项指定容器在后台运行；后面跟的/bin/bash可以是任意命令，只要容器支持即可；-P 表示容器内部端口随机映射到主机的高端口， -p 表示容器内部端口绑定到指定的主机端口； –name 选项可以显式给该容器指定一个名称，如果不指定，则docker自动给它分配一个名称 docker start|stop|restart|kill 启停容器 docker exec 在一个已经运行的容器中执行指定的命令，支持-d -i -t选项，含义和上面相同，如docker exec -it 43f7a65ec7f8 redis-cli docker rm 删除容器， -f选项表示通过SIGKILL信号强制删除 使用Docker启动 redis我使用的deepin linux，可以使用如下命令安装Docker： 12wget -qO- https://get.docker.com/ | shsudo service docker start 更换镜像源： 修改 /etc/docker/daemon.json 文件(没有则新建)，添加镜像源配置： 123&#123; &quot;registry-mirrors&quot;: [&quot;http://hub-mirror.c.163.com&quot;]&#125; 网易加速器：http://hub-mirror.c.163.com 官方中国加速器：https://registry.docker-cn.com ustc的镜像：https://docker.mirrors.ustc.edu.cn 用的debin，所以使用sudo service docker restart 重启docker生效。 ps: 用docker pull jenkins时上面几个repo的速度都不是很好，换成”http://f1361db2.m.daocloud.io&quot;之后才勉强下下来。 运行redis： 1docker run -p 6379:6379 --name local_redis -v $pwd/data:/data -d redis redis-server --appendonly yes -v $PWD/data:/data : 将主机中当前目录下的data挂载到容器的/data redis-server –appendonly yes : 在容器执行redis-server启动命令，并打开redis持久化配置 打开容器中的redis命令行： 1docker exec -it local_redis redis-cli 默认情况下，redis没有密码，使用config get requirepass查询可以看到密码是空，通过config set requirepass 123456来设置密码 使用Docker安装MySQL先下载镜像： sudo docker pull mysql 启动MySQL： 12345678910#启动docker run --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 -d mysql#进入容器docker exec -it mysql bash#登录mysqlmysql -u root -pALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;123456&#x27;;FLUSH PRIVILEGES; Docker 使用场景Docker我觉得是随着敏捷开发模式、微服务以及DevOps理念的流行，为实现快速集成快速发布应运而生的。在当前软件迭代以快为王的背景下，更快速，更轻量的方案越来越有生命力。相对与传统的物理机或虚拟机级别的服务，Docker 是进程级别的容器，粒度更小，也就更容易部署、运维和编排，而Docker镜像可以保存当前运行状态的快照，脱离宿主操作系统和软件版本等的限制，保证了环境一致性，一次配置，随处运行。 使用场景主要两方面： Devops 实现快速集成快速部署，配置code pipline可以实现代码提交后自动集成出包部署，极大提高开发调试效率。 轻量快速的启动移除特性使得Docker应用可以方便的进行负载均衡和弹性伸缩。 Docker 图形化管理工具其实命令行可以完成所有操作，但是Docker生态也有一些图形化界面的管理监控工具，常见的有DockerUI，Shipyard，Portainer。 使用docker search相应的镜像，以容器化方式启动即可。","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://example.com/tags/Docker/"}]},{"title":"Deepin安装后配置","slug":"Deepin_installation","date":"2019-05-23T01:09:33.000Z","updated":"2021-06-21T06:38:19.025Z","comments":true,"path":"2019/05/23/Deepin_installation/","link":"","permalink":"http://example.com/2019/05/23/Deepin_installation/","excerpt":"1 ll 提示找不到命令ll 不是 Linux的标准命令，而是ls -l的别称， 为了可以直接使用ll，可以把ll设置到~/.bashrc中。 把 alias ll=&#39;ls -l 加入~/.bashrc 文件末尾，执行 source ~/.bashrc 生效。","text":"1 ll 提示找不到命令ll 不是 Linux的标准命令，而是ls -l的别称， 为了可以直接使用ll，可以把ll设置到~/.bashrc中。 把 alias ll=&#39;ls -l 加入~/.bashrc 文件末尾，执行 source ~/.bashrc 生效。 2 安装java在Oracle官网下在JDK压缩包或者直接下载deb文件。 如果是deb文件安装，默认安装路径为/usr/lib/jvm/， 安装完成或者解压完成后，配置环境变量，在/etc/profile中添加; 123export JAVA_HOME=/usr/lib/jvm/jdk-12.0.1export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar source /etc/profile 使配置生效 3 安装maven在官网下载maven压缩包，解压到任意目录，在/etc/profile中配置环境变量： 12export MAVEN_HOME=/opt/apache-maven-3.6.1export PATH=$MAVEN_HOME/bin:$PATH source /etc/profile 使配置生效 安装IDEA在官网下载好压缩包之后，解压到任意路径，运行/bin/idea.sh 脚本启动， 启动好之后，在configuration中有一个create desktop entry的选项，可以创建桌面快捷方式。 后面可以通过快捷方式直接打开，该快捷方式也支持在任务栏驻留。 安装MySQL1sudo apt-get install mysql-server mysql-client 一个天坑是安装过程中根本没有让人输入密码，在普通用户下死活连不上mysql，后来发现，必须要用root去连接，要么在普通用户下用sudo mysql -u root -p 去连接，要么直接切到root，再连。 默认的密码会生成在 sudo cat /etc/mysql/debian.cnf 文件下，如果password是空的，则说明没有密码。 进入mysql命令行后，修改密码： 123use mysqlupdate user set authentication_string=password(&#x27;123456&#x27;) where user=&#x27;root&#x27;;FLUSH PRIVILEGES; 为了能在普通用户下连接mysql，使用如下命令设置： 12update mysql.user set plugin = &#x27;mysql_native_password&#x27; where user = &#x27;root&#x27;FLUSH PRIVILEGES; 然后sudo service mysqld restart重启服务","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"新疆旅行计划","slug":"xinjiang_plan","date":"2019-05-03T14:17:40.000Z","updated":"2021-06-21T06:38:19.884Z","comments":true,"path":"2019/05/03/xinjiang_plan/","link":"","permalink":"http://example.com/2019/05/03/xinjiang_plan/","excerpt":"2年前因姚璐的一本书与西藏与新疆结缘，一直想去看看真正的大山大河。今年因预算和身体问题未能成行，于是想着，利用这段缓冲期，做足准备，来年6月，新疆不见不散，因为有些地方，趁年轻没有去，或许就再也见不到了。","text":"2年前因姚璐的一本书与西藏与新疆结缘，一直想去看看真正的大山大河。今年因预算和身体问题未能成行，于是想着，利用这段缓冲期，做足准备，来年6月，新疆不见不散，因为有些地方，趁年轻没有去，或许就再也见不到了。 行前准备 1.5W ~ 2W RMB的预算 最迟在2020年春节后，开始约好同伴， 3~4 人最佳 摄影器材，看Money情况有 两个方案： A 家里的尼康 视情况买或租两个定焦广角镜头 B 网上租赁相机和镜头 从现在到20年4月，计划性的锻炼身体，成为一个日常习惯，尝试几次长途徒步 10KM+ 衣物、药物和杂物准备 买保险 买保险 买保险 重要的事情说三遍 时间7 8 9 10 是新疆的旅游黄金季，相应的价格也很感人，故考虑 5月底 6月初 出发， 旅行约 30 天左右。 去新疆前看情况 在甘肃一带走一圈。 路线30天行程，走大环线，打卡全部景点，北线→西线→南线→东线 走遍 ! 具体的景点和行程线路安排 在今年年底前安排好， 需要细化到具体的衣食住行、精确到小时","categories":[{"name":"Travel","slug":"Travel","permalink":"http://example.com/categories/Travel/"}],"tags":[{"name":"旅行","slug":"旅行","permalink":"http://example.com/tags/%E6%97%85%E8%A1%8C/"}]},{"title":"川藏旅行计划","slug":"tibet_plan","date":"2019-05-03T13:56:55.000Z","updated":"2021-06-21T06:38:19.869Z","comments":true,"path":"2019/05/03/tibet_plan/","link":"","permalink":"http://example.com/2019/05/03/tibet_plan/","excerpt":"开个头，具体行程在21年春节前安排好。","text":"开个头，具体行程在21年春节前安排好。 行前准备 预算 1W ~ 2W 保险","categories":[{"name":"Travel","slug":"Travel","permalink":"http://example.com/categories/Travel/"}],"tags":[{"name":"旅行","slug":"旅行","permalink":"http://example.com/tags/%E6%97%85%E8%A1%8C/"}]},{"title":"朝花夕拾_2019年度计划","slug":"2019_year_plan","date":"2019-05-03T01:45:27.000Z","updated":"2021-06-21T06:38:18.706Z","comments":true,"path":"2019/05/03/2019_year_plan/","link":"","permalink":"http://example.com/2019/05/03/2019_year_plan/","excerpt":"努力没有早晚 耕耘总有收获 2019 再出发 加油","text":"努力没有早晚 耕耘总有收获 2019 再出发 加油 工作生活 JAVA技术栈 达到5级分类法中3级的程度，即深入理解语言和流行框架的原理和应用 换一份工作 断舍离实践 （极简生活 裁剪欲望 谨慎的拥有 珍惜的使用 勇敢的舍弃） 每天早上早起半小时 锻炼30分钟 跑步 每个双休周末 至少参与一次支付宝线下公益或者豆瓣线下活动 兴趣培养-素描绘画达到一定熟练度 远离短半衰期的娱乐活动 书单 精读 有读后感 和 笔记 埃莱娜 &lt;那不勒斯四部曲&gt; 马伯庸 &lt;显微镜下的大明&gt; &lt;长安十二时辰&gt;重读 姚璐 &lt;世界那么大 我带你看看&gt; &lt;为什么要出发 因为远方在那里&gt; &lt;雪落香杉树&gt; 影单 是枝裕和 小偷家族 步履不停 比海更深 如父如子 新垣结衣 胜者即是正义12 逃避虽可耻但有用 我们无法成为野兽 唇上之歌 父女七日变 长泽雅美 海街日记 哪啊哪啊神去村 求婚大作战","categories":[{"name":"Emotion","slug":"Emotion","permalink":"http://example.com/categories/Emotion/"}],"tags":[{"name":"计划","slug":"计划","permalink":"http://example.com/tags/%E8%AE%A1%E5%88%92/"}]},{"title":"BLOG搭建记录","slug":"BLOG_bootstrap","date":"2019-05-03T01:24:38.000Z","updated":"2021-06-21T06:38:18.892Z","comments":true,"path":"2019/05/03/BLOG_bootstrap/","link":"","permalink":"http://example.com/2019/05/03/BLOG_bootstrap/","excerpt":"1 安装和配置GIT1.1 GIT安装： 下载 msysgit 并执行即可完成安装：git 1.2 配置SSH公钥： 使用下面的命令生成ssh公钥: 1ssh-keygen -t rsa -C &quot;your_email@youremail.com&quot;","text":"1 安装和配置GIT1.1 GIT安装： 下载 msysgit 并执行即可完成安装：git 1.2 配置SSH公钥： 使用下面的命令生成ssh公钥: 1ssh-keygen -t rsa -C &quot;your_email@youremail.com&quot; 进入~/.ssh目录下拷贝 id_rsa.pub 文件中的全部内容，进入github Account Settings，左边选择SSH Keys，Add SSH Key，title任意，内容粘贴之前复制的公钥，并保存： 为了验证是否成功，在git bash下输入： 1ssh -T git@github.com 如果是第一次的会提示是否continue，输入yes就会看到：You’ve successfully authenticated, but GitHub does not provide shell access 。这就表示已成功连上github。 1.3 配置本地GIT的用户名和Email: 12git config --global user.name &quot;your name&quot; git config --global user.email &quot;your_email@youremail.com&quot; 在github上建立一个repo，该工程即hexo博客工程，注意命名必须为your_user_name.github.io 2 安装Node.js安装Node.js: 到官网下载安装包 安装即可。 如果是linux系统， 在官网上下载node的压缩包，解压到本地任意路径下，如/opt/node/下，在bin目录下，有node和npm的可执行文件，一般情况下，我们需要在全局使用这两个命令，所以使用ln命令创建软连接，将这两个可执行文件映射到/usr/local/bin目录下： 123ln -s /opt/node-v10.15.3-linux-x64/bin/npm /usr/local/bin/ ln -s /opt/node-v10.15.3-linux-x64/bin/node /usr/local/bin/ 3 安装hexo和依赖包3.1 安装hexo 1npm install -g hexo 在linux系统下，如果输入hexo提示找不到该命令，可以先安装hexo-cli：npm install -g hexo-cli, 安装过程中，shell中会打印出hexo-cli的安装目录，在该安装目录的bin下面有一个名为hexo的可执行文件，同样的，创建软连接，以便在全局使用hexo命令： 1ln -s /usr/local/dev/node-v10.2/lib/node_modules/hexo-cli/bin/hexo /usr/local/bin/hexo 3.2 初始化 在本地创建放置hexo博客的文件夹，并在该文件夹下打开git bash窗口，使用hexo init命令初始化。 3.3 安装hexo依赖包： 注： 如下命令均在3.2中创建的hexo博客文件夹下进行 必选： 1234# 用于部署到github远程仓库npm install hexo-deployer-git --save# 用于使用命令hexo server 在本地启动hexo server运行博客npm install hexo-server --save 可选： 123456# 用于生成toc目录结构npm install hexo-toc --savenpm install hexo-renderer-less --savenpm install hexo-generator-feed --savenpm install hexo-generator-json-content --savenpm install hexo-helper-qrcode --save 4 配置并使用hexo4.1 配置远程仓库： 在hexo博客目录下，打开_config.yml配置文件，配置github远程仓库： 1234deploy: type: git repo: git@github.com:your_user_name/your_user_name.github.io.git branch: master 4.2 创建新博文： 1hexo new your_blog_name 创建的博文在~/source/_posts/ 目录下。 4.3 绑定域名：在~/source/目录下，新建一个文件，名称为CNAME， 编辑该文件，直接写入自己的域名，保存退出。 4.4 预览：在本地启动hexo server预览博客： 1hexo server 访问 http://localhost:4000/ 即可。 4.5 推送至远程仓库： 编辑好博文后，使用hexo g 生成转换后的html/js/静态文件等， 接下来使用hexo d 推送至远程仓库。 完成后即可访问自己域名 查看博客。 5 hexo 主题hexo提供了丰富的主题，主题的预览/安装/配置可参考官方主题站：hexo 主题列表 安装完成后， 在_config.yml配置文件中，通过theme: xxxxx选项指定主题。 ps: 切换主题后部署之前，建议使用hexo clean 先清理，以避免上一个主题生成的文件有残留。 6 附： my _config.yml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980# Hexo Configuration## Docs: https://hexo.io/docs/configuration.html## Source: https://github.com/hexojs/hexo/# Site #整站的基本信息title: #网站标题subtitle: #网站副标题description: #网站描述，给搜索引擎用的，在生成html中的head-&gt;meta中可看到author: #网站作者，在下方显示email: #联系邮箱language: zh-CN #语言# URL## If your site is put in a subdirectory, set url as &#x27;http://yoursite.com/child&#x27; and root as &#x27;/child/&#x27;url: http://xxxx #你的域名root: /permalink: :year/:month/:day/:title/permalink_defaults:# Directorysource_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render:# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: true # Open external links in new tabfilename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace:# Category &amp; Tagdefault_category: uncategorizedcategory_map:tag_map:# Date / Time format## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DDtime_format: HH:mm:ss# Pagination## Set per_page to 0 to disable paginationper_page: 10pagination_dir: page# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/#theme: hexo-theme-light#theme: jekyll#theme: alex#theme: indigotheme: maupassant#theme: Hacker# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: git@github.com:xxxx/xxxx.github.io.git branch: master","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"Mybatis01_概述","slug":"Mybatis01_about","date":"2019-05-02T13:43:33.000Z","updated":"2021-06-21T06:38:19.659Z","comments":true,"path":"2019/05/02/Mybatis01_about/","link":"","permalink":"http://example.com/2019/05/02/Mybatis01_about/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://example.com/tags/Mybatis/"}]},{"title":"Python复习笔记03_转型Python3","slug":"Python03_Python3","date":"2019-05-02T13:42:09.000Z","updated":"2021-06-21T06:38:19.734Z","comments":true,"path":"2019/05/02/Python03_Python3/","link":"","permalink":"http://example.com/2019/05/02/Python03_Python3/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"}]},{"title":"Python复习笔记02_yield关键字和基本的协程","slug":"Python02_yield_corutine","date":"2019-05-02T13:41:44.000Z","updated":"2021-06-21T06:38:19.723Z","comments":true,"path":"2019/05/02/Python02_yield_corutine/","link":"","permalink":"http://example.com/2019/05/02/Python02_yield_corutine/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"}]},{"title":"Python复习笔记01_深入装饰器和闭包","slug":"Python01_decorate_closure","date":"2019-05-02T13:41:22.000Z","updated":"2021-06-21T06:38:19.712Z","comments":true,"path":"2019/05/02/Python01_decorate_closure/","link":"","permalink":"http://example.com/2019/05/02/Python01_decorate_closure/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"}]},{"title":"JAVA技术栈复习笔记13_NIO","slug":"JAVA13_NIO","date":"2019-05-02T13:39:26.000Z","updated":"2021-06-21T06:38:19.557Z","comments":true,"path":"2019/05/02/JAVA13_NIO/","link":"","permalink":"http://example.com/2019/05/02/JAVA13_NIO/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://example.com/tags/JAVA/"}]},{"title":"JAVA技术栈复习笔记12_自定义注解","slug":"JAVA12_custom_anotation","date":"2019-05-02T13:39:05.000Z","updated":"2021-06-21T06:38:19.547Z","comments":true,"path":"2019/05/02/JAVA12_custom_anotation/","link":"","permalink":"http://example.com/2019/05/02/JAVA12_custom_anotation/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://example.com/tags/JAVA/"}]},{"title":"Spring04_SpringMVC","slug":"Spring04_SpringMVC","date":"2019-05-02T13:37:01.000Z","updated":"2021-06-21T06:38:19.810Z","comments":true,"path":"2019/05/02/Spring04_SpringMVC/","link":"","permalink":"http://example.com/2019/05/02/Spring04_SpringMVC/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"Spring01_概述","slug":"Spring01_about","date":"2019-05-02T13:36:45.000Z","updated":"2021-06-21T06:38:19.775Z","comments":true,"path":"2019/05/02/Spring01_about/","link":"","permalink":"http://example.com/2019/05/02/Spring01_about/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"Spring03_AOP","slug":"Spring03_AOP","date":"2019-05-02T13:36:34.000Z","updated":"2021-06-21T06:38:19.798Z","comments":true,"path":"2019/05/02/Spring03_AOP/","link":"","permalink":"http://example.com/2019/05/02/Spring03_AOP/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"Spring02_IOC","slug":"Spring02_IOC","date":"2019-05-02T13:36:23.000Z","updated":"2021-06-21T06:38:19.786Z","comments":true,"path":"2019/05/02/Spring02_IOC/","link":"","permalink":"http://example.com/2019/05/02/Spring02_IOC/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"Mybatis02_一对多多对多等","slug":"Mybatis02_mapping","date":"2019-05-02T13:35:38.000Z","updated":"2021-06-21T06:38:19.669Z","comments":true,"path":"2019/05/02/Mybatis02_mapping/","link":"","permalink":"http://example.com/2019/05/02/Mybatis02_mapping/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://example.com/tags/Mybatis/"}]},{"title":"设计模式04_适配器模式","slug":"design_pattern04_adapter","date":"2019-05-02T13:34:52.000Z","updated":"2021-06-21T06:38:19.204Z","comments":true,"path":"2019/05/02/design_pattern04_adapter/","link":"","permalink":"http://example.com/2019/05/02/design_pattern04_adapter/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"DesignPattern","slug":"DesignPattern","permalink":"http://example.com/tags/DesignPattern/"}]},{"title":"设计模式03_代理模式","slug":"design_pattern03_proxy","date":"2019-05-02T13:34:37.000Z","updated":"2021-06-21T06:38:19.158Z","comments":true,"path":"2019/05/02/design_pattern03_proxy/","link":"","permalink":"http://example.com/2019/05/02/design_pattern03_proxy/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"DesignPattern","slug":"DesignPattern","permalink":"http://example.com/tags/DesignPattern/"}]},{"title":"设计模式05-装饰器模式","slug":"design_pattern05_decorate","date":"2019-05-02T13:34:37.000Z","updated":"2021-06-21T06:38:19.249Z","comments":true,"path":"2019/05/02/design_pattern05_decorate/","link":"","permalink":"http://example.com/2019/05/02/design_pattern05_decorate/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"DesignPattern","slug":"DesignPattern","permalink":"http://example.com/tags/DesignPattern/"}]},{"title":"设计模式01_单例模式","slug":"design_pattern01_singleton","date":"2019-05-02T13:33:47.000Z","updated":"2021-06-21T06:38:19.068Z","comments":true,"path":"2019/05/02/design_pattern01_singleton/","link":"","permalink":"http://example.com/2019/05/02/design_pattern01_singleton/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"DesignPattern","slug":"DesignPattern","permalink":"http://example.com/tags/DesignPattern/"}]},{"title":"JAVA技术栈复习笔记10_文件IO","slug":"JAVA10_IO","date":"2019-05-02T13:32:36.000Z","updated":"2021-06-21T06:38:19.530Z","comments":true,"path":"2019/05/02/JAVA10_IO/","link":"","permalink":"http://example.com/2019/05/02/JAVA10_IO/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://example.com/tags/JAVA/"}]},{"title":"JAVA技术栈复习笔记09_并发（四）","slug":"JAVA09_concurrent04","date":"2019-05-02T13:29:44.000Z","updated":"2021-06-21T06:38:19.521Z","comments":true,"path":"2019/05/02/JAVA09_concurrent04/","link":"","permalink":"http://example.com/2019/05/02/JAVA09_concurrent04/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://example.com/tags/JAVA/"}]},{"title":"JAVA技术栈复习笔记08_并发（三）","slug":"JAVA08_concurrent03","date":"2019-05-02T13:29:10.000Z","updated":"2021-06-21T06:38:19.513Z","comments":true,"path":"2019/05/02/JAVA08_concurrent03/","link":"","permalink":"http://example.com/2019/05/02/JAVA08_concurrent03/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://example.com/tags/JAVA/"}]},{"title":"JAVA技术栈复习笔记07_并发（二）","slug":"JAVA07_concurrent02","date":"2019-05-02T13:28:51.000Z","updated":"2021-06-21T06:38:19.504Z","comments":true,"path":"2019/05/02/JAVA07_concurrent02/","link":"","permalink":"http://example.com/2019/05/02/JAVA07_concurrent02/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://example.com/tags/JAVA/"}]},{"title":"JAVA技术栈复习笔记06_并发（一）","slug":"JAVA06_concurrent01","date":"2019-05-02T13:28:28.000Z","updated":"2021-06-21T06:38:19.496Z","comments":true,"path":"2019/05/02/JAVA06_concurrent01/","link":"","permalink":"http://example.com/2019/05/02/JAVA06_concurrent01/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://example.com/tags/JAVA/"}]},{"title":"JAVA技术栈复习笔记05_集合类","slug":"JAVA05_Collection","date":"2019-05-02T13:27:52.000Z","updated":"2021-06-21T06:38:19.485Z","comments":true,"path":"2019/05/02/JAVA05_Collection/","link":"","permalink":"http://example.com/2019/05/02/JAVA05_Collection/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://example.com/tags/JAVA/"}]},{"title":"JAVA技术栈复习笔记04_GC机制","slug":"JAVA04_GC","date":"2019-05-02T13:27:24.000Z","updated":"2021-06-21T06:38:19.475Z","comments":true,"path":"2019/05/02/JAVA04_GC/","link":"","permalink":"http://example.com/2019/05/02/JAVA04_GC/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://example.com/tags/JAVA/"}]},{"title":"JAVA技术栈复习笔记03_内存模型","slug":"JAVA03_mem","date":"2019-05-02T13:27:02.000Z","updated":"2021-06-21T06:38:19.466Z","comments":true,"path":"2019/05/02/JAVA03_mem/","link":"","permalink":"http://example.com/2019/05/02/JAVA03_mem/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://example.com/tags/JAVA/"}]},{"title":"JAVA技术栈复习笔记02_泛型","slug":"JAVA02_generic","date":"2019-05-02T13:26:16.000Z","updated":"2021-06-21T06:38:19.456Z","comments":true,"path":"2019/05/02/JAVA02_generic/","link":"","permalink":"http://example.com/2019/05/02/JAVA02_generic/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://example.com/tags/JAVA/"}]},{"title":"JAVA技术栈复习笔记01_HashMap深入探究","slug":"JAVA01_HashMap","date":"2019-05-02T13:25:38.000Z","updated":"2021-06-21T06:38:19.444Z","comments":true,"path":"2019/05/02/JAVA01_HashMap/","link":"","permalink":"http://example.com/2019/05/02/JAVA01_HashMap/","excerpt":"","text":"","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://example.com/tags/JAVA/"}]},{"title":"过去 现在 未来","slug":"now","date":"2019-01-13T14:44:38.000Z","updated":"2021-06-21T06:38:19.702Z","comments":true,"path":"2019/01/13/now/","link":"","permalink":"http://example.com/2019/01/13/now/","excerpt":"","text":"因为上学早一年的原因，潜移默化间总觉得自己还小，而当下的生活境遇又时刻提醒着自己，已经不是小孩子了，角色上的变化让人时常觉得突兀。 今天IG夺冠了，Jackeylove 17岁拿了世界冠军，而我25岁，貌似还在自由生长着，犹豫着成为一棵怎样的树，又将扎根于哪里。想想，20岁前拼命的脱离家庭的束缚，而现在真的被放养了，才发现我不得不自己修建枝桠，而曾心心念念的自由原是春药也是毒药，难以驾驭，或许这就是这个年纪传统意义上要结婚生子，步入另一个阶段的原因，只要选择这个标准答案，所有的困惑就都落在万家灯火的一间，不必烦恼这些没有意义的问题。 生而平凡，注定有太多无法实现的梦，眼睛望着天空，脚还要踩在地下，这是着实痛苦，时间久了，便对所有的事情都变得佛系，比如取悦不了自己的爱情宁愿不要，被区别对待了也并无怨愤，只是，就这样佛系的过一生吗？ 所以，未来在哪里？","categories":[{"name":"Emotion","slug":"Emotion","permalink":"http://example.com/categories/Emotion/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"Nginx+uwsgi 部署 Django Web 项目","slug":"Nginx_uwsgi_deploy_DjangoWeb_proj","date":"2016-11-20T02:20:28.000Z","updated":"2021-06-21T06:38:19.691Z","comments":true,"path":"2016/11/20/Nginx_uwsgi_deploy_DjangoWeb_proj/","link":"","permalink":"http://example.com/2016/11/20/Nginx_uwsgi_deploy_DjangoWeb_proj/","excerpt":"Part1 环境 Ubuntu Server 14.04 Nginx uwsgi python3.x Django 1.10","text":"Part1 环境 Ubuntu Server 14.04 Nginx uwsgi python3.x Django 1.10 Part2 Django静态资源处理Django 静态资源配置-settings: Django 静态资源配置- urls: Django 在页面上引用静态资源: 部署之前需要cd 到项目目录下,执行: 1python3 manage.py collectstatic Part3 uwsgi配置参考:Setting up Django and your web server with uWSGI and nginx 先使用命令启动一下 uwsgi 看能否正常访问: 1uwsgi --http :80 --chdir /path/to/project --module yourprojectname.wsgi 访问 http://www.example.com/index.html 如果能正常访问,静态资源都能正常加载,再继续后面的步骤. 现在使用配置文件指定 uwsgi 的启动参数,在项目目录下(也可以在其他目录)新建一个 uwsgi 的启动参数配置文件,这个配置文件可以是 ini 也可以是 xml,此处使用 ini, 内容如下: 12345678910111213141516[uwsgi]chdir = /root/App #项目目录路径module = DjangoDemo.wsgi # 项目名称.wsgimaster = true processes = 2 # 核心数threads = 4 # 线程数chomd-socket = 664 #socket = /root/App/mysite.socksocket = 127.0.0.1:8001 # 监听本机8001端口 使用上述配置文件启动 uwsgi: 1uwsgi --ini mysite_uwsgi.ini # the --ini option is used to specify a file 注:如果想停止 uwsgi 服务,需要查询 uwsgi 的进程号,然后 kill 进程.查询进程命令: 1ps ef | grep uwsgi 终止进程: 1kill -9 100876 #-9表示强制,100876为进程号 启动好之后, uwsgi 会以 socket 方式监听本机的8001端口 Part3 Nginx 配置安装 Nignx 和需要的包: 1sudo apt-get install python-dev nginx 下载 uwsgi_params 文件,把该文件放在项目目录下(或其他目录),在 Nginx 配置文件中,需要指定该文件的路径. 在项目目录下(或其他目录)新建 Nginx 配置文件,内容如下: 12345678910111213141516171819202122232425262728293031323334# mysite_nginx.conf# the upstream component nginx needs to connect toupstream django &#123; # server unix:///path/to/your/mysite/mysite.sock; # for a file socket server 127.0.0.1:8001; # for a web port socket (we&#x27;ll use this first)&#125;# configuration of the serverserver &#123; # the port your site will be served on listen 80; # the domain name it will serve for server_name www.example.com; # substitute your machine&#x27;s IP address or FQDN charset utf-8; # max upload size client_max_body_size 75M; # adjust to taste # Django media location /media &#123; alias /path/to/your/mysite/media; # your Django project&#x27;s media files - amend as required &#125; location /static &#123; alias /path/to/your/mysite/static; # your Django project&#x27;s static files - amend as required &#125; # Finally, send all non-media requests to the Django server. location / &#123; uwsgi_pass django; include /path/to/your/mysite/uwsgi_params; # the uwsgi_params file you installed &#125;&#125; 这个配置文件指定了 Nginx 监听 HTTP 协议的80端口,凡是通过 Http 协议80端口过来的请求都会被转发给本机的8001端口处理,同时 Url 形如 www.example.com/static/xxx 或 www.example.com/media/xxx 时,Web资源请求会被转为访问上面配置的资源在服务器上的绝对路径 把上述配置文件 添加到 nginx 的可用站点中去,以使配置生效: 1sudo ln -s ~/path/to/your/mysite/mysite_nginx.conf /etc/nginx/sites-enabled/ 重启 Nginx 查看效果: 1sudo /etc/init.d/nginx restart 常见问题1 nginx静态资源文件无法访问，403 forbidden错误问题描述:配置的静态资源目录下面文件无法访问，浏览器访问出现403 forbidden. 解决方案:查看nginx的log文件，发现错误日志中静态文件访问都出现 Permission denied的权限错误，但是将存放静态资源的static目录赋予777的最高权限还是不能解决,最终解决方法是把nginx.conf配置文件(etc/nginx/ 下)中的user改成root. 2 Bad Request (400) Error问题描述:访问网站任何资源都提示 Bad Bad Request (400) 错误. 解决方案:新版Django的settings配置中需要指定允许访问的域名或 ip： 1234ALLOWED_HOSTS = [ &#x27;.example.com&#x27;, # Allow domain and subdomains &#x27;192.168.1.1&#x27;, # Also allow FQDN and subdomains] 3 invalid request block size: 21573 (max 4096)…skip问题描述:以uwsgi方式启动测试脚本时: 1uwsgi --socket :8080 --wsgi-file test.py -M -p 20 访问在浏览器输入http://0.0.0.0:8080/ 浏览器提示”未收到数据”，后台出现错误提示 1invalid request block size: 21573 (max 4096)...skip 错误原因:usgi参数-s表示以socket方式提供通信端口，默认的协议是tcp.通过浏览器访问使用的协议是http. 解决方案:直接提供http服务 1uwsgi --http :8080 --wsgi-file test.py -M -p 20 补充nginx与uwsgi有三种交互方式：http、tcp、unix本地sock. http方式主要是利用nginx的反向代理功能。 TCP方式是ngix通过tcp方式和uwsgi交互。 unix本地sock是通过本地的sock文件进行交互。 如果使用本地sokc方式，uwsgi的启动应该是 1uwsgi --socket /var/MyApp/MySite.sock --module MySite.wsgi 并且在nginx的upsteam中要配置MySite.sock文件地址. 如果是TCP方式，uwsig的启动应该是 1uwsgi --socket :13010 --module MySite.wsgi 并且在nginx的upsteam中配置Nginx 监听的ip和端口 采用反向代理方式，uwsgi的启动应该是 1uwsgi --http:13010 --module MySite.wsgi 同样在nginx的upsteam中配置Nginx 监听的ip和端口","categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"}]}],"categories":[{"name":"Technology","slug":"Technology","permalink":"http://example.com/categories/Technology/"},{"name":"Emotion","slug":"Emotion","permalink":"http://example.com/categories/Emotion/"},{"name":"摄影","slug":"摄影","permalink":"http://example.com/categories/%E6%91%84%E5%BD%B1/"},{"name":"Travel","slug":"Travel","permalink":"http://example.com/categories/Travel/"},{"name":"Poetry","slug":"Poetry","permalink":"http://example.com/categories/Poetry/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"},{"name":"JAVA 并发","slug":"JAVA-并发","permalink":"http://example.com/tags/JAVA-%E5%B9%B6%E5%8F%91/"},{"name":"DesignPattern","slug":"DesignPattern","permalink":"http://example.com/tags/DesignPattern/"},{"name":"框架","slug":"框架","permalink":"http://example.com/tags/%E6%A1%86%E6%9E%B6/"},{"name":"摄影 人文","slug":"摄影-人文","permalink":"http://example.com/tags/%E6%91%84%E5%BD%B1-%E4%BA%BA%E6%96%87/"},{"name":"JAVA","slug":"JAVA","permalink":"http://example.com/tags/JAVA/"},{"name":"旅行 西藏 摄影","slug":"旅行-西藏-摄影","permalink":"http://example.com/tags/%E6%97%85%E8%A1%8C-%E8%A5%BF%E8%97%8F-%E6%91%84%E5%BD%B1/"},{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"},{"name":"诗","slug":"诗","permalink":"http://example.com/tags/%E8%AF%97/"},{"name":"旅行","slug":"旅行","permalink":"http://example.com/tags/%E6%97%85%E8%A1%8C/"},{"name":"Deepin","slug":"Deepin","permalink":"http://example.com/tags/Deepin/"},{"name":"徒步","slug":"徒步","permalink":"http://example.com/tags/%E5%BE%92%E6%AD%A5/"},{"name":"断舍离","slug":"断舍离","permalink":"http://example.com/tags/%E6%96%AD%E8%88%8D%E7%A6%BB/"},{"name":"Docker","slug":"Docker","permalink":"http://example.com/tags/Docker/"},{"name":"计划","slug":"计划","permalink":"http://example.com/tags/%E8%AE%A1%E5%88%92/"},{"name":"Mybatis","slug":"Mybatis","permalink":"http://example.com/tags/Mybatis/"},{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"}]}